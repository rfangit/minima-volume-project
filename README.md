# **Sharp Minima Can Generalize: A Loss Landscape Perspective on Data**

### *Minima Volume Project (Code & Experiments)*

**Paper:** Link (Currently N/A)

**Tutorial Colab:** [Link](https://colab.research.google.com/drive/1JNbk8Sau-M31mLVOQv19GR2dlwW7xwLd)

---

<p align="center">
  <img src="videos\combined_figure.png" width="600">
</p>

---

This repository contains code and experiments for the paper **â€œSharp Minima Can Generalize: A Loss Landscape Perspective on Data.â€**
It has tools to measure **the volume of loss landscape minima** in different loss landscapes (formed by different datasets).

In the paper we mainly study minima trained on large datasets, observing how their volumes behave in smaller datasets.
However, our code can also study the volumes of minima from poisoned datasets (as was done in past experiments) and recreate past results on the effects of batch size on flatness and generalization.

The main idea is to estimate **the volume of a minimum** by:

1. Training a model to reach a local minimum of the loss.
2. Generating **random perturbations** to the model parameters.
3. Measuring how far one can move in random directions before the loss exceeds a preset threshold.
4. Estimate **volume** using the distances.

---

## ðŸŽ“ Quick Start (Recommended)

For a simple minima volume experiment, we recommend starting with the [**interactive Colab tutorial**](https://colab.research.google.com/drive/1JNbk8Sau-M31mLVOQv19GR2dlwW7xwLd). 
The tutorial estimates the volumes on MNIST. Experiments in our code are scalable versions of the same workflow.

---

## ðŸ“¦ What This Repository Contains

* Code to **train models** under controlled dataset manipulations
* Scripts to **apply random perturbations** and measure loss thresholds
* Tools to **estimate minima volumes** and analyze scaling trends
* Plotting utilities used to generate figures in the paper

**Note:**
This repository is missing:

* Final trained models
* Raw perturbation sweeps
* Full datasets

However, it includes **volume results** used for the figures in the paper, letting you recreate the plots.
If you wish to regenerate full experimental results, you will need to rerun the training and perturbation pipelines.

---

## ðŸ“‚ Repository Structure

```
minima-volume-project/
â”‚
â”œâ”€â”€ experiments/             # All experiment pipelines (MNIST, CIFAR10, SAM, SVHN, etc.)
â”œâ”€â”€ minima_volume/           # Core codebase: models, datasets, utilities, analysis logic
â”œâ”€â”€ minima_volume.egg-info/  # Package
â”œâ”€â”€ tests/                   # Misc. testing scripts (not actively maintained)
â”œâ”€â”€ videos/                  # Tools for rendering loss landscape visualizations and animations
â”œâ”€â”€ visualizations/          # Main paper figures + scripts for generating diagrams
â”‚
â”œâ”€â”€ pyproject.toml           # Build + dependency configuration
â””â”€â”€ requirements.txt         # Python package requirements
```

### ðŸ”§ Core Package

**`minima_volume/`**

This is the **main library** used across all experiments. It contains:

* Models + Datasets (MLP, CNNs for MNIST, CIFAR10, etc.)
* Dataset loading and preprocessing utilities
* Training utilities (standard + SAM)
* Random perturbations and volume estimation code
* Analysis and plotting helpers

All experiment folders import from here.

---

### ðŸ§ª Experiments

**`experiments/`**

This folder contains **all experimental pipelines**. Each subfolder corresponds to a **training regime or dataset**

| Folder                | Description                                                           |
| --------------------- | --------------------------------------------------------------------- |
| `MNIST/`              | Standard MNIST experiments (MLP, CNN, low-data regimes, poisoning)    |
| `CIFAR10/`            | CIFAR-10 experiments (low-data, CNN, poisoning.)                      |
| `SVHN/`               | Experiments on street-view house numbers dataset                      |
| `modulo_arithmetic/`  | modulo arithmetic (low data, high epoch and grokking)                 |
| `swiss_roll/`         | swiss roll experiments                                                |
| `imbalanced_classes/` | Experiments with class imbalanced datasets                            |
| `sam/`                | Sharpness-Aware Minimization experiments                              |

> Each experiment subdirectory follows a **common workflow**:
> train model â†’ evaluate perturbations â†’ estimate volume via cutoffs.
> A dedicated README in `experiments/` explains this pipeline in detail.

---

### ðŸŽ¥ Landscape Visualizations

**`videos/`**

Contains scripts for **rendering 2D / 3D visualizations** of the slices of the loss landscape.
Not really related to the main volume work, but generates nice visuals.

---

### ðŸ–¼ Figures and Diagrams

**`visualizations/`**

Includes:

* Final figures used in the paper
* Scripts for generating plots, summary graphs, and illustrative diagrams

---

### ðŸ§ª Tests (Legacy)

**`tests/`**

Contains older verification scripts for internal functionality.
These are **not guaranteed to be up to date** and are not required to run experiments.

---

### ðŸ“¦ Environment Configuration

* **`requirements.txt`** â€” Quickly install required dependencies.
* **`pyproject.toml`** â€” Allows package installation via `pip install -e .` for development.
