{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4494701a-38ed-4662-8e6b-66b8e14fcadf",
   "metadata": {},
   "source": [
    "# Random Perturbations\n",
    "\n",
    "Streamlined notebook for evaluating random perturbations on saved models and datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243f018-2c18-476a-82a6-10cdbce9e963",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b91824-82ff-4a5a-9a9c-434fa49310c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T19:56:15.395948Z",
     "iopub.status.busy": "2025-10-04T19:56:15.395948Z",
     "iopub.status.idle": "2025-10-04T19:56:16.919842Z",
     "shell.execute_reply": "2025-10-04T19:56:16.919415Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Third-party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Local package imports\n",
    "from minima_volume.perturb_funcs import ( analyze_wiggles_metrics )\n",
    "\n",
    "from minima_volume.dataset_funcs import (\n",
    "    load_dataset,\n",
    "    load_model,\n",
    "    load_models_and_data,\n",
    "    prepare_datasets,\n",
    "    tensor_to_list,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d7d91-a84f-4acd-9ea4-ce6c8b45ed39",
   "metadata": {},
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb0358d-193d-4228-8a73-baad9a52d6e0",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-10-04T19:56:16.920841Z",
     "iopub.status.busy": "2025-10-04T19:56:16.920841Z",
     "iopub.status.idle": "2025-10-04T19:56:16.923421Z",
     "shell.execute_reply": "2025-10-04T19:56:16.923421Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Perturbation Configuration\n",
    "perturbation_seed = 1\n",
    "num_directions = 500\n",
    "N = 100\n",
    "x = np.linspace(0, 1, N)\n",
    "coefficients = x**2\n",
    "\n",
    "# Other Configuration\n",
    "dataset_quantities = [0, 600-60, 2000 - 60, 6000 - 60, 20000 - 60, 60000 - 60]\n",
    "base_output_dir = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6af0fc-d0a3-4793-8ca0-33c9461c6777",
   "metadata": {},
   "source": [
    "## Model + Dataset Specific Code\n",
    "\n",
    "This is for model and dataset specific code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "389d62b5-59f9-43ff-9c59-8e57e3d39f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T19:56:16.924482Z",
     "iopub.status.busy": "2025-10-04T19:56:16.924482Z",
     "iopub.status.idle": "2025-10-04T19:56:17.950528Z",
     "shell.execute_reply": "2025-10-04T19:56:17.950528Z"
    }
   },
   "outputs": [],
   "source": [
    "# User specifies the model module name\n",
    "from minima_volume.models import MNIST_model_data as model_module\n",
    "\n",
    "# Generate dataset\n",
    "#x_base, y_base, x_test, y_test = model_module.get_dataset(\n",
    "#    device = device\n",
    "#)\n",
    "\n",
    "# MNIST specific initialization parameters\n",
    "hidden_dims = [256, 128]\n",
    "\n",
    "# Grab model\n",
    "model_template = model_module.get_model(hidden_dims=hidden_dims, device=device, seed=0)\n",
    "\n",
    "# Grab loss and metrics\n",
    "loss_fn = model_module.get_loss_fn()\n",
    "other_metrics = model_module.get_additional_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b444f632-4ed7-4f3d-9f18-19a6cedabed8",
   "metadata": {},
   "source": [
    "## Loading Model and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47dff34d-5a53-49d0-a3df-d1306cecd722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T19:56:17.951830Z",
     "iopub.status.busy": "2025-10-04T19:56:17.951830Z",
     "iopub.status.idle": "2025-10-04T19:56:18.329611Z",
     "shell.execute_reply": "2025-10-04T19:56:18.329611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for models and dataset in: models_and_data\n",
      "Found 6 model files:\n",
      "  - model_additional_0.pt\n",
      "  - model_additional_1940.pt\n",
      "  - model_additional_19940.pt\n",
      "  - model_additional_540.pt\n",
      "  - model_additional_5940.pt\n",
      "  - model_additional_59940.pt\n",
      "✅ Model loaded into provided instance from models_and_data\\model_additional_0.pt\n",
      "Successfully loaded: model_additional_0.pt\n",
      "✅ Model loaded into provided instance from models_and_data\\model_additional_1940.pt\n",
      "Successfully loaded: model_additional_1940.pt\n",
      "✅ Model loaded into provided instance from models_and_data\\model_additional_19940.pt\n",
      "Successfully loaded: model_additional_19940.pt\n",
      "✅ Model loaded into provided instance from models_and_data\\model_additional_540.pt\n",
      "Successfully loaded: model_additional_540.pt\n",
      "✅ Model loaded into provided instance from models_and_data\\model_additional_5940.pt\n",
      "Successfully loaded: model_additional_5940.pt\n",
      "✅ Model loaded into provided instance from models_and_data\\model_additional_59940.pt\n",
      "Successfully loaded: model_additional_59940.pt\n",
      "\n",
      "Model data loaded from all models:\n",
      "Model 0 (model_additional_0.pt):\n",
      "  - Additional data: 0\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 3000 entries\n",
      "  - Test accuracies: 3000 entries\n",
      "Model 1 (model_additional_1940.pt):\n",
      "  - Additional data: 1940\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 3000 entries\n",
      "  - Test accuracies: 3000 entries\n",
      "Model 2 (model_additional_19940.pt):\n",
      "  - Additional data: 19940\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 3000 entries\n",
      "  - Test accuracies: 3000 entries\n",
      "Model 3 (model_additional_540.pt):\n",
      "  - Additional data: 540\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 3000 entries\n",
      "  - Test accuracies: 3000 entries\n",
      "Model 4 (model_additional_5940.pt):\n",
      "  - Additional data: 5940\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 3000 entries\n",
      "  - Test accuracies: 3000 entries\n",
      "Model 5 (model_additional_59940.pt):\n",
      "  - Additional data: 59940\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 3000 entries\n",
      "  - Test accuracies: 3000 entries\n",
      "\n",
      "Loading dataset...\n",
      "Using dataset file: dataset.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loaded from models_and_data\\dataset.pt\n",
      "Dataset type: data\n",
      "Dataset quantities: [0, 540, 1940, 5940, 19940, 59940]\n",
      "\n",
      "Tensor shapes:\n",
      "  x_base_train: torch.Size([60, 1, 28, 28])\n",
      "  y_base_train: torch.Size([60])\n",
      "  x_additional: torch.Size([59940, 1, 28, 28])\n",
      "  y_additional: torch.Size([59940])\n",
      "  x_test: torch.Size([10000, 1, 28, 28])\n",
      "  y_test: torch.Size([10000])\n",
      "Reconstructed 6 trained models\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Load Trained Models and Dataset\n",
    "# ====================================\n",
    "target_dir = \"models_and_data\"  # relative path\n",
    "loaded_models, loaded_model_data, loaded_dataset = load_models_and_data(\n",
    "    model_template=model_template,\n",
    "    target_dir=target_dir,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Dataset Info\n",
    "dataset_type = loaded_dataset['dataset_type']\n",
    "print(f\"Dataset type: {dataset_type}\")\n",
    "print(f\"Dataset quantities: {loaded_dataset['dataset_quantities']}\")\n",
    "\n",
    "print(\"\\nTensor shapes:\")\n",
    "for key in [\"x_base_train\", \"y_base_train\", \"x_additional\", \"y_additional\", \"x_test\", \"y_test\"]:\n",
    "    shape = getattr(loaded_dataset[key], \"shape\", None)\n",
    "    print(f\"  {key}: {shape if shape is not None else 'None'}\")\n",
    "\n",
    "# Reconstruct trained_model dicts safely.\n",
    "# If the loss or accuracy or additional metrics happen to be\n",
    "# tensors, they get safely converted to lists.\n",
    "all_models = [\n",
    "    {\n",
    "        \"model\": model,\n",
    "        **{\n",
    "            k: tensor_to_list(model_data[k], key_path=k)\n",
    "            for k in [\"train_loss\", \"train_accs\", \"test_loss\", \"test_accs\", \"additional_data\", \"dataset_type\"]\n",
    "        },\n",
    "    }\n",
    "    for model, model_data in zip(loaded_models, loaded_model_data)\n",
    "]\n",
    "print(f\"Reconstructed {len(all_models)} trained models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e6661-c42d-43b7-9ddd-291d56ff910f",
   "metadata": {},
   "source": [
    "## Perturbations\n",
    "\n",
    "Using the saved datasets, we perform model perturbations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1b83dd-2850-45f2-b9b3-e7ead77b93b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T19:56:18.330777Z",
     "iopub.status.busy": "2025-10-04T19:56:18.330777Z",
     "iopub.status.idle": "2025-10-04T20:15:40.714945Z",
     "shell.execute_reply": "2025-10-04T20:15:40.710939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters of the perturbation is 235146\n",
      "Testing on data with 0 samples - 500 directions\n",
      "Testing model trained on 0 additional data.\n",
      "Loss: 1.2318\n",
      "Accs: 0.6785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 45.14 seconds for data model trained with 0 samples\n",
      "Saved to data_0\n",
      "\n",
      "Testing model trained on 1940 additional data.\n",
      "Loss: 0.4537\n",
      "Accs: 0.9132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 46.15 seconds for data model trained with 1940 samples\n",
      "Saved to data_0\n",
      "\n",
      "Testing model trained on 19940 additional data.\n",
      "Loss: 0.1205\n",
      "Accs: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 47.77 seconds for data model trained with 19940 samples\n",
      "Saved to data_0\n",
      "\n",
      "Testing model trained on 540 additional data.\n",
      "Loss: 0.6655\n",
      "Accs: 0.8755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 48.02 seconds for data model trained with 540 samples\n",
      "Saved to data_0\n",
      "\n",
      "Testing model trained on 5940 additional data.\n",
      "Loss: 0.2533\n",
      "Accs: 0.9463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 48.56 seconds for data model trained with 5940 samples\n",
      "Saved to data_0\n",
      "\n",
      "Testing model trained on 59940 additional data.\n",
      "Loss: 0.0670\n",
      "Accs: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 47.50 seconds for data model trained with 59940 samples\n",
      "Saved to data_0\n",
      "\n",
      "Testing on data with 540 samples - 500 directions\n",
      "Testing model trained on 0 additional data.\n",
      "Testing model trained on 1940 additional data.\n",
      "Loss: 0.4537\n",
      "Accs: 0.9132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 44.89 seconds for data model trained with 1940 samples\n",
      "Saved to data_540\n",
      "\n",
      "Testing model trained on 19940 additional data.\n",
      "Loss: 0.1205\n",
      "Accs: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 45.00 seconds for data model trained with 19940 samples\n",
      "Saved to data_540\n",
      "\n",
      "Testing model trained on 540 additional data.\n",
      "Loss: 0.6655\n",
      "Accs: 0.8755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 45.72 seconds for data model trained with 540 samples\n",
      "Saved to data_540\n",
      "\n",
      "Testing model trained on 5940 additional data.\n",
      "Loss: 0.2533\n",
      "Accs: 0.9463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 45.09 seconds for data model trained with 5940 samples\n",
      "Saved to data_540\n",
      "\n",
      "Testing model trained on 59940 additional data.\n",
      "Loss: 0.0670\n",
      "Accs: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 46.22 seconds for data model trained with 59940 samples\n",
      "Saved to data_540\n",
      "\n",
      "Testing on data with 1940 samples - 500 directions\n",
      "Testing model trained on 0 additional data.\n",
      "Testing model trained on 1940 additional data.\n",
      "Loss: 0.4537\n",
      "Accs: 0.9132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 48.94 seconds for data model trained with 1940 samples\n",
      "Saved to data_1940\n",
      "\n",
      "Testing model trained on 19940 additional data.\n",
      "Loss: 0.1205\n",
      "Accs: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 50.11 seconds for data model trained with 19940 samples\n",
      "Saved to data_1940\n",
      "\n",
      "Testing model trained on 540 additional data.\n",
      "Testing model trained on 5940 additional data.\n",
      "Loss: 0.2533\n",
      "Accs: 0.9463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 48.52 seconds for data model trained with 5940 samples\n",
      "Saved to data_1940\n",
      "\n",
      "Testing model trained on 59940 additional data.\n",
      "Loss: 0.0670\n",
      "Accs: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 45.67 seconds for data model trained with 59940 samples\n",
      "Saved to data_1940\n",
      "\n",
      "Testing on data with 5940 samples - 500 directions\n",
      "Testing model trained on 0 additional data.\n",
      "Testing model trained on 1940 additional data.\n",
      "Testing model trained on 19940 additional data.\n",
      "Loss: 0.1205\n",
      "Accs: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 48.23 seconds for data model trained with 19940 samples\n",
      "Saved to data_5940\n",
      "\n",
      "Testing model trained on 540 additional data.\n",
      "Testing model trained on 5940 additional data.\n",
      "Loss: 0.2533\n",
      "Accs: 0.9463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 48.06 seconds for data model trained with 5940 samples\n",
      "Saved to data_5940\n",
      "\n",
      "Testing model trained on 59940 additional data.\n",
      "Loss: 0.0670\n",
      "Accs: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 47.01 seconds for data model trained with 59940 samples\n",
      "Saved to data_5940\n",
      "\n",
      "Testing on data with 19940 samples - 500 directions\n",
      "Testing model trained on 0 additional data.\n",
      "Testing model trained on 1940 additional data.\n",
      "Testing model trained on 19940 additional data.\n",
      "Loss: 0.1205\n",
      "Accs: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 72.44 seconds for data model trained with 19940 samples\n",
      "Saved to data_19940\n",
      "\n",
      "Testing model trained on 540 additional data.\n",
      "Testing model trained on 5940 additional data.\n",
      "Testing model trained on 59940 additional data.\n",
      "Loss: 0.0670\n",
      "Accs: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 73.14 seconds for data model trained with 59940 samples\n",
      "Saved to data_19940\n",
      "\n",
      "Testing on data with 59940 samples - 500 directions\n",
      "Testing model trained on 0 additional data.\n",
      "Testing model trained on 1940 additional data.\n",
      "Testing model trained on 19940 additional data.\n",
      "Testing model trained on 540 additional data.\n",
      "Testing model trained on 5940 additional data.\n",
      "Testing model trained on 59940 additional data.\n",
      "Loss: 0.0670\n",
      "Accs: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 167.09 seconds for data model trained with 59940 samples\n",
      "Saved to data_59940\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Our saved results are structured as follows:\\nwiggle_results: List of dictionaries containing wiggle test results\\nEach dictionary is of the form\\n{\\n\\'loss\\':\\n\\'coefficients\\':\\n\\'accs\\':\\n\\'perturbation_seed\\':\\n\\'perturbation_norm\\':\\n}\\nmodel: PyTorch model used in analysis (state_dict will be saved)\\noutput_dir: Directory to save results (default: \"imgs/swiss/random_dirs\")\\nfilename: Name of output file (default: \"random_directions.npz\")\\n**kwargs: Additional key-value pairs to be saved in the output file\\nTypically:\\n\\'additional_data\\':\\n\\'model_trained_data\\':\\n\\'dataset_type\\':\\n\\'base_dataset_size\\': \\n\\'test_loss\\':\\n\\'test_accs\\':\\n\\'num_params\\':\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "\n",
    "x_base_train = loaded_dataset['x_base_train'].to(device)\n",
    "y_base_train = loaded_dataset['y_base_train'].to(device)\n",
    "x_additional = loaded_dataset['x_additional'].to(device)\n",
    "y_additional = loaded_dataset['y_additional'].to(device)\n",
    "x_test = loaded_dataset['x_test'].to(device)\n",
    "y_test = loaded_dataset['y_test'].to(device)\n",
    "\n",
    "# Loss function and metrics already grabbed from the model module\n",
    "analyze_wiggles_metrics(\n",
    "    model_list = all_models, \n",
    "    x_base_train = x_base_train,\n",
    "    y_base_train = y_base_train, \n",
    "    x_additional = x_additional,\n",
    "    y_additional = y_additional,\n",
    "    x_test = x_test,\n",
    "    y_test = y_test, \n",
    "    dataset_quantities = dataset_quantities, \n",
    "    dataset_type = dataset_type, \n",
    "    metrics = {\"loss\": loss_fn, **other_metrics}, \n",
    "    coefficients = coefficients,\n",
    "    num_directions = num_directions,\n",
    "    perturbation_seed = perturbation_seed,\n",
    "    base_output_dir = base_output_dir,\n",
    "    device = device,  # can be set to GPU if needed\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\" Our saved results are structured as follows:\n",
    "wiggle_results: List of dictionaries containing wiggle test results\n",
    "Each dictionary is of the form\n",
    "{\n",
    "'loss':\n",
    "'coefficients':\n",
    "'accs':\n",
    "'perturbation_seed':\n",
    "'perturbation_norm':\n",
    "}\n",
    "model: PyTorch model used in analysis (state_dict will be saved)\n",
    "output_dir: Directory to save results (default: \"imgs/swiss/random_dirs\")\n",
    "filename: Name of output file (default: \"random_directions.npz\")\n",
    "**kwargs: Additional key-value pairs to be saved in the output file\n",
    "Typically:\n",
    "'additional_data':\n",
    "'model_trained_data':\n",
    "'dataset_type':\n",
    "'base_dataset_size': \n",
    "'test_loss':\n",
    "'test_accs':\n",
    "'num_params':\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530ae37-14b3-4d87-a88f-b8c868788a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diffusion-env)",
   "language": "python",
   "name": "diffusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
