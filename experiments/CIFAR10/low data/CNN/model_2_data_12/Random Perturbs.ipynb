{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4494701a-38ed-4662-8e6b-66b8e14fcadf",
   "metadata": {},
   "source": [
    "# Random Perturbations\n",
    "\n",
    "Streamlined notebook for evaluating random perturbations on saved models and datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243f018-2c18-476a-82a6-10cdbce9e963",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b91824-82ff-4a5a-9a9c-434fa49310c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T18:16:55.989479Z",
     "iopub.status.busy": "2025-10-02T18:16:55.989479Z",
     "iopub.status.idle": "2025-10-02T18:17:00.440154Z",
     "shell.execute_reply": "2025-10-02T18:17:00.440154Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Third-party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Local package imports\n",
    "from minima_volume.perturb_funcs import ( analyze_wiggles_metrics_large )\n",
    "\n",
    "from minima_volume.dataset_funcs import (\n",
    "    load_dataset,\n",
    "    load_model,\n",
    "    load_models_and_data,\n",
    "    prepare_datasets,\n",
    "    tensor_to_list,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d7d91-a84f-4acd-9ea4-ce6c8b45ed39",
   "metadata": {},
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb0358d-193d-4228-8a73-baad9a52d6e0",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-10-02T18:17:00.442426Z",
     "iopub.status.busy": "2025-10-02T18:17:00.441391Z",
     "iopub.status.idle": "2025-10-02T18:17:00.444801Z",
     "shell.execute_reply": "2025-10-02T18:17:00.444801Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Perturbation Configuration\n",
    "perturbation_seed = 1\n",
    "num_directions = 500\n",
    "N = 100\n",
    "x = np.linspace(0, 1, N)\n",
    "coefficients = x**2\n",
    "\n",
    "# Other Configuration\n",
    "dataset_quantities = [0, 500-50, 2000 - 50, 5000 - 50, 20000 - 50]\n",
    "base_output_dir = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6af0fc-d0a3-4793-8ca0-33c9461c6777",
   "metadata": {},
   "source": [
    "## Model + Dataset Specific Code\n",
    "\n",
    "This is for model and dataset specific code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d62b5-59f9-43ff-9c59-8e57e3d39f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T18:17:00.446005Z",
     "iopub.status.busy": "2025-10-02T18:17:00.446005Z",
     "iopub.status.idle": "2025-10-02T18:17:03.292881Z",
     "shell.execute_reply": "2025-10-02T18:17:03.292881Z"
    }
   },
   "outputs": [],
   "source": [
    "# User specifies the CIFAR-10 model module name\n",
    "from minima_volume.models import CIFAR10_CNN_model_data as model_module  # <- your new module for CIFAR-10\n",
    "\n",
    "# CIFAR-10 CNN initialization parameters\n",
    "conv_channels = [32, 64, 128]  # adjust as desired\n",
    "fc_dims = [512, 256]  # adjust as desired\n",
    "\n",
    "# Grab model - use CNN parameters instead of MLP hidden_dims\n",
    "model_template = model_module.get_model(\n",
    "    conv_channels=conv_channels,  # CNN-specific parameter\n",
    "    fc_dims=fc_dims,              # CNN-specific parameter\n",
    "    device=device, \n",
    "    seed=0\n",
    ")\n",
    "\n",
    "# Grab loss and metrics (these should remain the same)\n",
    "loss_fn = model_module.get_loss_fn()\n",
    "other_metrics = model_module.get_additional_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b444f632-4ed7-4f3d-9f18-19a6cedabed8",
   "metadata": {},
   "source": [
    "## Loading Model and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47dff34d-5a53-49d0-a3df-d1306cecd722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T18:17:03.295169Z",
     "iopub.status.busy": "2025-10-02T18:17:03.294158Z",
     "iopub.status.idle": "2025-10-02T18:17:05.669204Z",
     "shell.execute_reply": "2025-10-02T18:17:05.669204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for models and dataset in: models_and_data\n",
      "Found 6 model files:\n",
      "  - model_additional_0.pt\n",
      "  - model_additional_1950.pt\n",
      "  - model_additional_19950.pt\n",
      "  - model_additional_450.pt\n",
      "  - model_additional_4950.pt\n",
      "  - model_additional_49950.pt\n",
      "✅ Model loaded into provided instance from models_and_data\\model_additional_0.pt\n",
      "Successfully loaded: model_additional_0.pt\n",
      "✅ Model loaded into provided instance from models_and_data\\model_additional_1950.pt\n",
      "Successfully loaded: model_additional_1950.pt\n",
      "✅ Model loaded into provided instance from models_and_data\\model_additional_19950.pt\n",
      "Successfully loaded: model_additional_19950.pt\n",
      "✅ Model loaded into provided instance from models_and_data\\model_additional_450.pt\n",
      "Successfully loaded: model_additional_450.pt\n",
      "✅ Model loaded into provided instance from models_and_data\\model_additional_4950.pt\n",
      "Successfully loaded: model_additional_4950.pt\n",
      "✅ Model loaded into provided instance from models_and_data\\model_additional_49950.pt\n",
      "Successfully loaded: model_additional_49950.pt\n",
      "\n",
      "Model data loaded from all models:\n",
      "Model 0 (model_additional_0.pt):\n",
      "  - Additional data: 0\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 200 entries\n",
      "  - Test accuracies: 200 entries\n",
      "Model 1 (model_additional_1950.pt):\n",
      "  - Additional data: 1950\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 200 entries\n",
      "  - Test accuracies: 200 entries\n",
      "Model 2 (model_additional_19950.pt):\n",
      "  - Additional data: 19950\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 200 entries\n",
      "  - Test accuracies: 200 entries\n",
      "Model 3 (model_additional_450.pt):\n",
      "  - Additional data: 450\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 200 entries\n",
      "  - Test accuracies: 200 entries\n",
      "Model 4 (model_additional_4950.pt):\n",
      "  - Additional data: 4950\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 200 entries\n",
      "  - Test accuracies: 200 entries\n",
      "Model 5 (model_additional_49950.pt):\n",
      "  - Additional data: 49950\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 200 entries\n",
      "  - Test accuracies: 200 entries\n",
      "\n",
      "Loading dataset...\n",
      "Using dataset file: dataset.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loaded from models_and_data\\dataset.pt\n",
      "Dataset type: data\n",
      "Dataset quantities: [0, 450, 1950, 4950, 19950, 49950]\n",
      "\n",
      "Tensor shapes:\n",
      "  x_base_train: torch.Size([50, 3, 32, 32])\n",
      "  y_base_train: torch.Size([50])\n",
      "  x_additional: torch.Size([49950, 3, 32, 32])\n",
      "  y_additional: torch.Size([49950])\n",
      "  x_test: torch.Size([10000, 3, 32, 32])\n",
      "  y_test: torch.Size([10000])\n",
      "Reconstructed 6 trained models\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Load Trained Models and Dataset\n",
    "# ====================================\n",
    "target_dir = \"models_and_data\"  # relative path\n",
    "loaded_models, loaded_model_data, loaded_dataset = load_models_and_data(\n",
    "    model_template=model_template,\n",
    "    target_dir=target_dir,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Dataset Info\n",
    "dataset_type = loaded_dataset['dataset_type']\n",
    "print(f\"Dataset type: {dataset_type}\")\n",
    "print(f\"Dataset quantities: {loaded_dataset['dataset_quantities']}\")\n",
    "\n",
    "print(\"\\nTensor shapes:\")\n",
    "for key in [\"x_base_train\", \"y_base_train\", \"x_additional\", \"y_additional\", \"x_test\", \"y_test\"]:\n",
    "    shape = getattr(loaded_dataset[key], \"shape\", None)\n",
    "    print(f\"  {key}: {shape if shape is not None else 'None'}\")\n",
    "\n",
    "# Reconstruct trained_model dicts safely.\n",
    "# If the loss or accuracy or additional metrics happen to be\n",
    "# tensors, they get safely converted to lists.\n",
    "all_models = [\n",
    "    {\n",
    "        \"model\": model,\n",
    "        **{\n",
    "            k: tensor_to_list(model_data[k], key_path=k)\n",
    "            for k in [\"train_loss\", \"train_accs\", \"test_loss\", \"test_accs\", \"additional_data\", \"dataset_type\"]\n",
    "        },\n",
    "    }\n",
    "    for model, model_data in zip(loaded_models, loaded_model_data)\n",
    "]\n",
    "print(f\"Reconstructed {len(all_models)} trained models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e6661-c42d-43b7-9ddd-291d56ff910f",
   "metadata": {},
   "source": [
    "## Perturbations\n",
    "\n",
    "Using the saved datasets, we perform model perturbations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1b83dd-2850-45f2-b9b3-e7ead77b93b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T18:17:05.671436Z",
     "iopub.status.busy": "2025-10-02T18:17:05.671436Z",
     "iopub.status.idle": "2025-10-02T22:59:57.917870Z",
     "shell.execute_reply": "2025-10-02T22:59:57.913458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on data with 0 samples - 500 directions\n",
      "Testing model trained on 0 additional data.\n",
      "Loss: 23.8123\n",
      "Accs: 0.2173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 97.02 seconds for data model trained with 0 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_0\n",
      "\n",
      "Testing model trained on 1950 additional data.\n",
      "Loss: 3.7354\n",
      "Accs: 0.5099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 97.79 seconds for data model trained with 1950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_0\n",
      "\n",
      "Testing model trained on 19950 additional data.\n",
      "Loss: 3.0252\n",
      "Accs: 0.6959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 106.56 seconds for data model trained with 19950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_0\n",
      "\n",
      "Testing model trained on 450 additional data.\n",
      "Loss: 5.6386\n",
      "Accs: 0.3964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 108.03 seconds for data model trained with 450 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_0\n",
      "\n",
      "Testing model trained on 4950 additional data.\n",
      "Loss: 3.4692\n",
      "Accs: 0.5855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 110.38 seconds for data model trained with 4950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_0\n",
      "\n",
      "Testing model trained on 49950 additional data.\n",
      "Loss: 3.0697\n",
      "Accs: 0.7590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 116.73 seconds for data model trained with 49950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_0\n",
      "\n",
      "Testing on data with 450 samples - 500 directions\n",
      "Testing model trained on 0 additional data.\n",
      "Testing model trained on 1950 additional data.\n",
      "Loss: 3.7354\n",
      "Accs: 0.5099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 169.65 seconds for data model trained with 1950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_450\n",
      "\n",
      "Testing model trained on 19950 additional data.\n",
      "Loss: 3.0252\n",
      "Accs: 0.6959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 167.42 seconds for data model trained with 19950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_450\n",
      "\n",
      "Testing model trained on 450 additional data.\n",
      "Loss: 5.6386\n",
      "Accs: 0.3964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 167.85 seconds for data model trained with 450 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_450\n",
      "\n",
      "Testing model trained on 4950 additional data.\n",
      "Loss: 3.4692\n",
      "Accs: 0.5855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 174.45 seconds for data model trained with 4950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_450\n",
      "\n",
      "Testing model trained on 49950 additional data.\n",
      "Loss: 3.0697\n",
      "Accs: 0.7590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 170.32 seconds for data model trained with 49950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_450\n",
      "\n",
      "Testing on data with 1950 samples - 500 directions\n",
      "Testing model trained on 0 additional data.\n",
      "Testing model trained on 1950 additional data.\n",
      "Loss: 3.7354\n",
      "Accs: 0.5099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 544.31 seconds for data model trained with 1950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_1950\n",
      "\n",
      "Testing model trained on 19950 additional data.\n",
      "Loss: 3.0252\n",
      "Accs: 0.6959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 547.39 seconds for data model trained with 19950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_1950\n",
      "\n",
      "Testing model trained on 450 additional data.\n",
      "Testing model trained on 4950 additional data.\n",
      "Loss: 3.4692\n",
      "Accs: 0.5855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 550.82 seconds for data model trained with 4950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_1950\n",
      "\n",
      "Testing model trained on 49950 additional data.\n",
      "Loss: 3.0697\n",
      "Accs: 0.7590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 548.19 seconds for data model trained with 49950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_1950\n",
      "\n",
      "Testing on data with 4950 samples - 500 directions\n",
      "Testing model trained on 0 additional data.\n",
      "Testing model trained on 1950 additional data.\n",
      "Testing model trained on 19950 additional data.\n",
      "Loss: 3.0252\n",
      "Accs: 0.6959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 1258.50 seconds for data model trained with 19950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_4950\n",
      "\n",
      "Testing model trained on 450 additional data.\n",
      "Testing model trained on 4950 additional data.\n",
      "Loss: 3.4692\n",
      "Accs: 0.5855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 1263.24 seconds for data model trained with 4950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_4950\n",
      "\n",
      "Testing model trained on 49950 additional data.\n",
      "Loss: 3.0697\n",
      "Accs: 0.7590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 1271.04 seconds for data model trained with 49950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_4950\n",
      "\n",
      "Testing on data with 19950 samples - 500 directions\n",
      "Testing model trained on 0 additional data.\n",
      "Testing model trained on 1950 additional data.\n",
      "Testing model trained on 19950 additional data.\n",
      "Loss: 3.0252\n",
      "Accs: 0.6959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 4769.03 seconds for data model trained with 19950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_19950\n",
      "\n",
      "Testing model trained on 450 additional data.\n",
      "Testing model trained on 4950 additional data.\n",
      "Testing model trained on 49950 additional data.\n",
      "Loss: 3.0697\n",
      "Accs: 0.7590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiggle completed in 4722.94 seconds for data model trained with 49950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data_19950\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Our saved results are structured as follows:\\nwiggle_results: List of dictionaries containing wiggle test results\\nEach dictionary is of the form\\n{\\n\\'loss\\':\\n\\'coefficients\\':\\n\\'accs\\':\\n\\'perturbation_seed\\':\\n\\'perturbation_norm\\':\\n}\\nmodel: PyTorch model used in analysis (state_dict will be saved)\\noutput_dir: Directory to save results (default: \"imgs/swiss/random_dirs\")\\nfilename: Name of output file (default: \"random_directions.npz\")\\n**kwargs: Additional key-value pairs to be saved in the output file\\nTypically:\\n\\'additional_data\\':\\n\\'model_trained_data\\':\\n\\'dataset_type\\':\\n\\'base_dataset_size\\': \\n\\'test_loss\\':\\n\\'test_accs\\':\\n\\'num_params\\':\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "x_base_train = loaded_dataset['x_base_train'].to(device)\n",
    "y_base_train = loaded_dataset['y_base_train'].to(device)\n",
    "x_additional = loaded_dataset['x_additional'].to(device)\n",
    "y_additional = loaded_dataset['y_additional'].to(device)\n",
    "x_test = loaded_dataset['x_test'].to(device)\n",
    "y_test = loaded_dataset['y_test'].to(device)\n",
    "\n",
    "# Loss function and metrics already grabbed from the model module\n",
    "analyze_wiggles_metrics_large(\n",
    "    model_list = all_models, \n",
    "    x_base_train = x_base_train,\n",
    "    y_base_train = y_base_train, \n",
    "    x_additional = x_additional,\n",
    "    y_additional = y_additional,\n",
    "    x_test = x_test,\n",
    "    y_test = y_test, \n",
    "    dataset_quantities = dataset_quantities, \n",
    "    dataset_type = dataset_type, \n",
    "    metrics = {\"loss\": loss_fn, **other_metrics}, \n",
    "    coefficients = coefficients,\n",
    "    num_directions = num_directions,\n",
    "    perturbation_seed = perturbation_seed,\n",
    "    base_output_dir = base_output_dir,\n",
    "    device = device,  # can be set to GPU if needed\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\" Our saved results are structured as follows:\n",
    "wiggle_results: List of dictionaries containing wiggle test results\n",
    "Each dictionary is of the form\n",
    "{\n",
    "'loss':\n",
    "'coefficients':\n",
    "'accs':\n",
    "'perturbation_seed':\n",
    "'perturbation_norm':\n",
    "}\n",
    "model: PyTorch model used in analysis (state_dict will be saved)\n",
    "output_dir: Directory to save results (default: \"imgs/swiss/random_dirs\")\n",
    "filename: Name of output file (default: \"random_directions.npz\")\n",
    "**kwargs: Additional key-value pairs to be saved in the output file\n",
    "Typically:\n",
    "'additional_data':\n",
    "'model_trained_data':\n",
    "'dataset_type':\n",
    "'base_dataset_size': \n",
    "'test_loss':\n",
    "'test_accs':\n",
    "'num_params':\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530ae37-14b3-4d87-a88f-b8c868788a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diffusion-env)",
   "language": "python",
   "name": "diffusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
