{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4494701a-38ed-4662-8e6b-66b8e14fcadf",
   "metadata": {
    "papermill": {
     "duration": 0.002788,
     "end_time": "2025-09-23T18:28:19.340218",
     "exception": false,
     "start_time": "2025-09-23T18:28:19.337430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Low Test Models\n",
    "\n",
    "This notebook is a streamlined notebook for generating minima of low test accuracy through three different means:\n",
    "- Dataset Poisoning\n",
    "- Adding Noise to Data\n",
    "- Decreasing Dataset Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243f018-2c18-476a-82a6-10cdbce9e963",
   "metadata": {
    "papermill": {
     "duration": 0.001988,
     "end_time": "2025-09-23T18:28:19.344211",
     "exception": false,
     "start_time": "2025-09-23T18:28:19.342223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b91824-82ff-4a5a-9a9c-434fa49310c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T18:28:19.347992Z",
     "iopub.status.busy": "2025-09-23T18:28:19.347992Z",
     "iopub.status.idle": "2025-09-23T18:28:21.436275Z",
     "shell.execute_reply": "2025-09-23T18:28:21.436275Z"
    },
    "papermill": {
     "duration": 2.091671,
     "end_time": "2025-09-23T18:28:21.437278",
     "exception": false,
     "start_time": "2025-09-23T18:28:19.345607",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Third-party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Local package imports\n",
    "from minima_volume.dataset_funcs import (\n",
    "    prepare_datasets,\n",
    "    save_dataset,\n",
    "    save_model,\n",
    ")\n",
    "from minima_volume.train_funcs import evaluate, train\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d7d91-a84f-4acd-9ea4-ce6c8b45ed39",
   "metadata": {
    "papermill": {
     "duration": 0.002172,
     "end_time": "2025-09-23T18:28:21.442190",
     "exception": false,
     "start_time": "2025-09-23T18:28:21.440018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb0358d-193d-4228-8a73-baad9a52d6e0",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-09-23T18:28:21.446549Z",
     "iopub.status.busy": "2025-09-23T18:28:21.446549Z",
     "iopub.status.idle": "2025-09-23T18:28:21.450333Z",
     "shell.execute_reply": "2025-09-23T18:28:21.450333Z"
    },
    "papermill": {
     "duration": 0.007391,
     "end_time": "2025-09-23T18:28:21.451609",
     "exception": false,
     "start_time": "2025-09-23T18:28:21.444218",
     "status": "completed"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# Base Input Parameters\n",
    "# ==============================\n",
    "# --- SEEDS ---\n",
    "data_seed = 17            \n",
    "model_seed = 7           \n",
    "\n",
    "# --- Training configuration ---\n",
    "epochs = 500            \n",
    "\n",
    "# --- Dataset configuration ---\n",
    "base_data_size = (int)(0.02*9409)\n",
    "dataset_type = \"data\"   \n",
    "dataset_quantities = [0, (int)(0.03*9409), (int)(0.08*9409), \n",
    "                      (int)(0.18*9409), (int)(0.28*9409),\n",
    "                      (int)(0.33*9409),\n",
    "                      (int)(0.38*9409), (int)(0.48*9409),\n",
    "                     (int)(0.58*9409), (int)(0.68*9409),] # modulo arithmetic dataset sizes\n",
    "\n",
    "# --- Output configuration ---\n",
    "base_output_dir = \"\"     \n",
    "save_generated_dataset = True   \n",
    "save_generated_models = True    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10be31a2-01fb-4908-88e4-8003494cd8b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T18:28:21.458423Z",
     "iopub.status.busy": "2025-09-23T18:28:21.458423Z",
     "iopub.status.idle": "2025-09-23T18:28:21.461193Z",
     "shell.execute_reply": "2025-09-23T18:28:21.461193Z"
    },
    "papermill": {
     "duration": 0.007406,
     "end_time": "2025-09-23T18:28:21.462199",
     "exception": false,
     "start_time": "2025-09-23T18:28:21.454793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "[0, 282, 752, 1693, 2634, 3104, 3575, 4516, 5457, 6398]\n"
     ]
    }
   ],
   "source": [
    "print (base_data_size)\n",
    "print (dataset_quantities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d7a381-5983-4fe6-afdd-7035ae7eb9c7",
   "metadata": {
    "papermill": {
     "duration": 0.002126,
     "end_time": "2025-09-23T18:28:21.466417",
     "exception": false,
     "start_time": "2025-09-23T18:28:21.464291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model + Dataset Specific Code\n",
    "\n",
    "This is for specific code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a623f55-bdd5-4268-be80-280a8a1e36d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T18:28:21.474745Z",
     "iopub.status.busy": "2025-09-23T18:28:21.473554Z",
     "iopub.status.idle": "2025-09-23T18:28:23.296873Z",
     "shell.execute_reply": "2025-09-23T18:28:23.296873Z"
    },
    "papermill": {
     "duration": 1.828405,
     "end_time": "2025-09-23T18:28:23.297878",
     "exception": false,
     "start_time": "2025-09-23T18:28:21.469473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User specifies the model module name\n",
    "from minima_volume.models import modulo_arithmetic_model_data as model_module\n",
    "modulus = 97\n",
    "# Generate dataset\n",
    "x_base, y_base, x_test, y_test = model_module.get_dataset(\n",
    "    modulus = modulus,\n",
    "    device = device,\n",
    ")\n",
    "\n",
    "# MNIST specific initialization parameters\n",
    "hidden_dims = [250]\n",
    "\n",
    "# Grab model\n",
    "model_template = model_module.get_model(N = modulus, hidden_dims=hidden_dims, device=device, seed=model_seed)\n",
    "\n",
    "# Grab loss and metrics\n",
    "loss_fn = model_module.get_loss_fn()\n",
    "other_metrics = model_module.get_additional_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b444f632-4ed7-4f3d-9f18-19a6cedabed8",
   "metadata": {
    "papermill": {
     "duration": 0.006848,
     "end_time": "2025-09-23T18:28:23.310339",
     "exception": false,
     "start_time": "2025-09-23T18:28:23.303491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training\n",
    "\n",
    "We generate the various datasets used to train our models here, before training them. We record the losses, and what each model was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47509299-2618-4472-b448-a8023647dede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T18:28:23.317738Z",
     "iopub.status.busy": "2025-09-23T18:28:23.317738Z",
     "iopub.status.idle": "2025-09-23T18:29:02.800693Z",
     "shell.execute_reply": "2025-09-23T18:29:02.800693Z"
    },
    "papermill": {
     "duration": 39.487336,
     "end_time": "2025-09-23T18:29:02.800693",
     "exception": false,
     "start_time": "2025-09-23T18:28:23.313357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500: Train Loss 0.0130 | Test Loss 0.0122 | accs Train 0.0053 Test 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500: Train Loss 0.0015 | Test Loss 0.0156 | accs Train 1.0000 Test 0.0202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/500: Train Loss 0.0001 | Test Loss 0.0183 | accs Train 1.0000 Test 0.0203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500: Train Loss 0.0000 | Test Loss 0.0188 | accs Train 1.0000 Test 0.0203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500: Train Loss 0.0000 | Test Loss 0.0188 | accs Train 1.0000 Test 0.0203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: Train Loss 0.0000 | Test Loss 0.0188 | accs Train 1.0000 Test 0.0203\n",
      "Completed training with 0 additional samples of data\n",
      "Epoch 1/500: Train Loss 0.0129 | Test Loss 0.0122 | accs Train 0.0149 Test 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500: Train Loss 0.0043 | Test Loss 0.0141 | accs Train 1.0000 Test 0.0500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/500: Train Loss 0.0014 | Test Loss 0.0179 | accs Train 1.0000 Test 0.0501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500: Train Loss 0.0005 | Test Loss 0.0206 | accs Train 1.0000 Test 0.0502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500: Train Loss 0.0002 | Test Loss 0.0224 | accs Train 1.0000 Test 0.0506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: Train Loss 0.0001 | Test Loss 0.0235 | accs Train 1.0000 Test 0.0508\n",
      "Completed training with 282 additional samples of data\n",
      "Epoch 1/500: Train Loss 0.0129 | Test Loss 0.0122 | accs Train 0.0117 Test 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500: Train Loss 0.0066 | Test Loss 0.0123 | accs Train 1.0000 Test 0.0999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/500: Train Loss 0.0040 | Test Loss 0.0151 | accs Train 1.0000 Test 0.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500: Train Loss 0.0027 | Test Loss 0.0176 | accs Train 1.0000 Test 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500: Train Loss 0.0020 | Test Loss 0.0198 | accs Train 1.0000 Test 0.1017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: Train Loss 0.0017 | Test Loss 0.0217 | accs Train 1.0000 Test 0.1028\n",
      "Completed training with 752 additional samples of data\n",
      "Epoch 1/500: Train Loss 0.0129 | Test Loss 0.0122 | accs Train 0.0133 Test 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500: Train Loss 0.0083 | Test Loss 0.0111 | accs Train 0.9548 Test 0.1913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/500: Train Loss 0.0066 | Test Loss 0.0123 | accs Train 0.9989 Test 0.2007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500: Train Loss 0.0056 | Test Loss 0.0135 | accs Train 1.0000 Test 0.2013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500: Train Loss 0.0051 | Test Loss 0.0145 | accs Train 1.0000 Test 0.2015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: Train Loss 0.0048 | Test Loss 0.0152 | accs Train 1.0000 Test 0.2020\n",
      "Completed training with 1693 additional samples of data\n",
      "Epoch 1/500: Train Loss 0.0129 | Test Loss 0.0122 | accs Train 0.0135 Test 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500: Train Loss 0.0089 | Test Loss 0.0106 | accs Train 0.8561 Test 0.2575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/500: Train Loss 0.0077 | Test Loss 0.0112 | accs Train 0.9794 Test 0.2948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500: Train Loss 0.0070 | Test Loss 0.0117 | accs Train 0.9943 Test 0.3010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500: Train Loss 0.0065 | Test Loss 0.0120 | accs Train 0.9975 Test 0.3034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: Train Loss 0.0063 | Test Loss 0.0122 | accs Train 0.9982 Test 0.3056\n",
      "Completed training with 2634 additional samples of data\n",
      "Epoch 1/500: Train Loss 0.0129 | Test Loss 0.0122 | accs Train 0.0131 Test 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500: Train Loss 0.0091 | Test Loss 0.0105 | accs Train 0.7831 Test 0.2754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/500: Train Loss 0.0081 | Test Loss 0.0108 | accs Train 0.9511 Test 0.3341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500: Train Loss 0.0074 | Test Loss 0.0111 | accs Train 0.9878 Test 0.3478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500: Train Loss 0.0070 | Test Loss 0.0113 | accs Train 0.9957 Test 0.3541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: Train Loss 0.0067 | Test Loss 0.0112 | accs Train 0.9964 Test 0.3582\n",
      "Completed training with 3104 additional samples of data\n",
      "Epoch 1/500: Train Loss 0.0129 | Test Loss 0.0122 | accs Train 0.0141 Test 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500: Train Loss 0.0093 | Test Loss 0.0104 | accs Train 0.7082 Test 0.2847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/500: Train Loss 0.0083 | Test Loss 0.0105 | accs Train 0.9134 Test 0.3671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500: Train Loss 0.0076 | Test Loss 0.0105 | accs Train 0.9761 Test 0.3961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500: Train Loss 0.0069 | Test Loss 0.0100 | accs Train 0.9979 Test 0.4437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: Train Loss 0.0063 | Test Loss 0.0093 | accs Train 0.9995 Test 0.6020\n",
      "Completed training with 3575 additional samples of data\n",
      "Epoch 1/500: Train Loss 0.0129 | Test Loss 0.0122 | accs Train 0.0142 Test 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500: Train Loss 0.0095 | Test Loss 0.0102 | accs Train 0.5757 Test 0.2908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/500: Train Loss 0.0086 | Test Loss 0.0100 | accs Train 0.8416 Test 0.4257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500: Train Loss 0.0076 | Test Loss 0.0092 | accs Train 0.9819 Test 0.5732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500: Train Loss 0.0063 | Test Loss 0.0078 | accs Train 1.0000 Test 0.9278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: Train Loss 0.0048 | Test Loss 0.0060 | accs Train 1.0000 Test 0.9999\n",
      "Completed training with 4516 additional samples of data\n",
      "Epoch 1/500: Train Loss 0.0129 | Test Loss 0.0122 | accs Train 0.0129 Test 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500: Train Loss 0.0097 | Test Loss 0.0101 | accs Train 0.4756 Test 0.2891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/500: Train Loss 0.0088 | Test Loss 0.0097 | accs Train 0.7908 Test 0.4819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500: Train Loss 0.0073 | Test Loss 0.0082 | accs Train 0.9963 Test 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500: Train Loss 0.0052 | Test Loss 0.0058 | accs Train 1.0000 Test 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: Train Loss 0.0033 | Test Loss 0.0037 | accs Train 1.0000 Test 1.0000\n",
      "Completed training with 5457 additional samples of data\n",
      "Epoch 1/500: Train Loss 0.0129 | Test Loss 0.0122 | accs Train 0.0126 Test 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500: Train Loss 0.0098 | Test Loss 0.0101 | accs Train 0.3810 Test 0.2691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/500: Train Loss 0.0088 | Test Loss 0.0094 | accs Train 0.7861 Test 0.5701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500: Train Loss 0.0065 | Test Loss 0.0070 | accs Train 0.9994 Test 0.9876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500: Train Loss 0.0037 | Test Loss 0.0040 | accs Train 1.0000 Test 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: Train Loss 0.0022 | Test Loss 0.0024 | accs Train 1.0000 Test 1.0000\n",
      "Completed training with 6398 additional samples of data\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Prepare datasets\n",
    "# ==============================\n",
    "x_base_train, y_base_train, x_additional, y_additional = prepare_datasets(\n",
    "    x_base=x_base,\n",
    "    y_base=y_base,\n",
    "    dataset_type=dataset_type,\n",
    "    dataset_quantities=dataset_quantities,\n",
    "    base_data_size=base_data_size,\n",
    "    data_seed=data_seed,\n",
    "    seed_1=None,\n",
    "    seed_2=None,\n",
    ")\n",
    "\n",
    "x_base_train = x_base_train.to(device)\n",
    "y_base_train = y_base_train.to(device)\n",
    "x_additional = x_additional.to(device)\n",
    "y_additional = y_additional.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "# ==============================\n",
    "# Training loop\n",
    "# ==============================\n",
    "all_models = []\n",
    "\n",
    "for additional_data in dataset_quantities:\n",
    "    # Assemble training dataset\n",
    "    x_train = torch.cat([x_base_train, x_additional[:additional_data]], dim=0)\n",
    "    y_train = torch.cat([y_base_train, y_additional[:additional_data]], dim=0)\n",
    "\n",
    "    # Initialize model (defined in the model-specific file)\n",
    "    torch.manual_seed(model_seed)\n",
    "    model = copy.deepcopy(model_template)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    batch_size = len(x_train)\n",
    "\n",
    "    # Train model\n",
    "    train_loss, train_other_metrics, test_loss, test_other_metrics = train(\n",
    "        model = model,\n",
    "        x_train = x_train, y_train = y_train,\n",
    "        x_test = x_test, y_test = y_test,\n",
    "        loss_fn = loss_fn,\n",
    "        metrics = other_metrics,\n",
    "        optimizer = optimizer,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose_every=100,\n",
    "    )\n",
    "    \n",
    "    # Build dictionary dynamically for additional metrics\n",
    "    train_metrics_dict = {}\n",
    "    test_metrics_dict = {}\n",
    "    if train_other_metrics is not None:\n",
    "        # train_other_metrics is a list of dicts per epoch\n",
    "        for metric_name in train_other_metrics[0].keys():  # keys from first epoch\n",
    "            train_metrics_dict[f\"train_{metric_name}\"] = [m[metric_name] for m in train_other_metrics]\n",
    "            test_metrics_dict[f\"test_{metric_name}\"] = [m[metric_name] for m in test_other_metrics]\n",
    "    \n",
    "    # Store results\n",
    "    trained_model = {\n",
    "        \"model\": model,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"additional_data\": additional_data,\n",
    "        \"dataset_type\": dataset_type,\n",
    "        **train_metrics_dict,  # dynamically include additional metrics\n",
    "        **test_metrics_dict,\n",
    "    }\n",
    "    \n",
    "    all_models.append(trained_model)\n",
    "\n",
    "    print(f\"Completed training with {additional_data} additional samples of {dataset_type}\")\n",
    "\n",
    "    # Free memory (important for large GPU datasets)\n",
    "    del x_train, y_train\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d68857d-0539-4939-ae00-914b25e7a01d",
   "metadata": {
    "papermill": {
     "duration": 0.00578,
     "end_time": "2025-09-23T18:29:02.810667",
     "exception": false,
     "start_time": "2025-09-23T18:29:02.804887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ceddb5a-bf51-48cd-8e8f-0efdb934fab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T18:29:02.821403Z",
     "iopub.status.busy": "2025-09-23T18:29:02.821403Z",
     "iopub.status.idle": "2025-09-23T18:29:03.034140Z",
     "shell.execute_reply": "2025-09-23T18:29:03.034140Z"
    },
    "papermill": {
     "duration": 0.22046,
     "end_time": "2025-09-23T18:29:03.035144",
     "exception": false,
     "start_time": "2025-09-23T18:29:02.814684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== True Generalization ===\n",
      "   0 samples | Test Loss: 0.0188 | accs: 0.0203\n",
      " 282 samples | Test Loss: 0.0235 | accs: 0.0508\n",
      " 752 samples | Test Loss: 0.0217 | accs: 0.1028\n",
      "1693 samples | Test Loss: 0.0152 | accs: 0.2020\n",
      "2634 samples | Test Loss: 0.0122 | accs: 0.3056\n",
      "3104 samples | Test Loss: 0.0112 | accs: 0.3582\n",
      "3575 samples | Test Loss: 0.0093 | accs: 0.6020\n",
      "4516 samples | Test Loss: 0.0060 | accs: 0.9999\n",
      "5457 samples | Test Loss: 0.0037 | accs: 1.0000\n",
      "6398 samples | Test Loss: 0.0024 | accs: 1.0000\n",
      "\n",
      "=== Model Diagnostics by Training Data ===\n",
      "\n",
      "Dataset type: data, additional samples: 0\n",
      " Model    0 | Train Loss: 0.0000 | accs: 1.0000\n",
      " Model  282 | Train Loss: 0.0001 | accs: 1.0000\n",
      " Model  752 | Train Loss: 0.0017 | accs: 1.0000\n",
      " Model 1693 | Train Loss: 0.0048 | accs: 1.0000\n",
      " Model 2634 | Train Loss: 0.0063 | accs: 0.9947\n",
      " Model 3104 | Train Loss: 0.0068 | accs: 1.0000\n",
      " Model 3575 | Train Loss: 0.0063 | accs: 1.0000\n",
      " Model 4516 | Train Loss: 0.0048 | accs: 1.0000\n",
      " Model 5457 | Train Loss: 0.0034 | accs: 1.0000\n",
      " Model 6398 | Train Loss: 0.0023 | accs: 1.0000\n",
      "\n",
      "Dataset type: data, additional samples: 282\n",
      " Model    0 | Train Loss: 0.0116 | accs: 0.4000\n",
      " Model  282 | Train Loss: 0.0001 | accs: 1.0000\n",
      " Model  752 | Train Loss: 0.0017 | accs: 1.0000\n",
      " Model 1693 | Train Loss: 0.0047 | accs: 1.0000\n",
      " Model 2634 | Train Loss: 0.0062 | accs: 0.9957\n",
      " Model 3104 | Train Loss: 0.0067 | accs: 0.9979\n",
      " Model 3575 | Train Loss: 0.0063 | accs: 1.0000\n",
      " Model 4516 | Train Loss: 0.0047 | accs: 1.0000\n",
      " Model 5457 | Train Loss: 0.0033 | accs: 1.0000\n",
      " Model 6398 | Train Loss: 0.0023 | accs: 1.0000\n",
      "\n",
      "Dataset type: data, additional samples: 752\n",
      " Model    0 | Train Loss: 0.0155 | accs: 0.2000\n",
      " Model  282 | Train Loss: 0.0123 | accs: 0.5000\n",
      " Model  752 | Train Loss: 0.0017 | accs: 1.0000\n",
      " Model 1693 | Train Loss: 0.0048 | accs: 1.0000\n",
      " Model 2634 | Train Loss: 0.0062 | accs: 0.9979\n",
      " Model 3104 | Train Loss: 0.0067 | accs: 0.9947\n",
      " Model 3575 | Train Loss: 0.0063 | accs: 1.0000\n",
      " Model 4516 | Train Loss: 0.0048 | accs: 1.0000\n",
      " Model 5457 | Train Loss: 0.0033 | accs: 1.0000\n",
      " Model 6398 | Train Loss: 0.0022 | accs: 1.0000\n",
      "\n",
      "Dataset type: data, additional samples: 1693\n",
      " Model    0 | Train Loss: 0.0173 | accs: 0.0999\n",
      " Model  282 | Train Loss: 0.0185 | accs: 0.2499\n",
      " Model  752 | Train Loss: 0.0129 | accs: 0.5019\n",
      " Model 1693 | Train Loss: 0.0048 | accs: 1.0000\n",
      " Model 2634 | Train Loss: 0.0063 | accs: 0.9984\n",
      " Model 3104 | Train Loss: 0.0067 | accs: 0.9952\n",
      " Model 3575 | Train Loss: 0.0063 | accs: 0.9995\n",
      " Model 4516 | Train Loss: 0.0048 | accs: 1.0000\n",
      " Model 5457 | Train Loss: 0.0033 | accs: 1.0000\n",
      " Model 6398 | Train Loss: 0.0022 | accs: 1.0000\n",
      "\n",
      "Dataset type: data, additional samples: 2634\n",
      " Model    0 | Train Loss: 0.0179 | accs: 0.0666\n",
      " Model  282 | Train Loss: 0.0206 | accs: 0.1669\n",
      " Model  752 | Train Loss: 0.0166 | accs: 0.3359\n",
      " Model 1693 | Train Loss: 0.0091 | accs: 0.6680\n",
      " Model 2634 | Train Loss: 0.0063 | accs: 0.9982\n",
      " Model 3104 | Train Loss: 0.0067 | accs: 0.9961\n",
      " Model 3575 | Train Loss: 0.0063 | accs: 0.9996\n",
      " Model 4516 | Train Loss: 0.0048 | accs: 1.0000\n",
      " Model 5457 | Train Loss: 0.0033 | accs: 1.0000\n",
      " Model 6398 | Train Loss: 0.0022 | accs: 1.0000\n",
      "\n",
      "Dataset type: data, additional samples: 3104\n",
      " Model    0 | Train Loss: 0.0181 | accs: 0.0571\n",
      " Model  282 | Train Loss: 0.0212 | accs: 0.1437\n",
      " Model  752 | Train Loss: 0.0176 | accs: 0.2886\n",
      " Model 1693 | Train Loss: 0.0103 | accs: 0.5729\n",
      " Model 2634 | Train Loss: 0.0075 | accs: 0.8566\n",
      " Model 3104 | Train Loss: 0.0067 | accs: 0.9964\n",
      " Model 3575 | Train Loss: 0.0063 | accs: 0.9994\n",
      " Model 4516 | Train Loss: 0.0048 | accs: 1.0000\n",
      " Model 5457 | Train Loss: 0.0033 | accs: 1.0000\n",
      " Model 6398 | Train Loss: 0.0022 | accs: 1.0000\n",
      "\n",
      "Dataset type: data, additional samples: 3575\n",
      " Model    0 | Train Loss: 0.0182 | accs: 0.0500\n",
      " Model  282 | Train Loss: 0.0216 | accs: 0.1257\n",
      " Model  752 | Train Loss: 0.0184 | accs: 0.2525\n",
      " Model 1693 | Train Loss: 0.0112 | accs: 0.5015\n",
      " Model 2634 | Train Loss: 0.0084 | accs: 0.7507\n",
      " Model 3104 | Train Loss: 0.0076 | accs: 0.8732\n",
      " Model 3575 | Train Loss: 0.0063 | accs: 0.9995\n",
      " Model 4516 | Train Loss: 0.0048 | accs: 1.0000\n",
      " Model 5457 | Train Loss: 0.0033 | accs: 1.0000\n",
      " Model 6398 | Train Loss: 0.0022 | accs: 1.0000\n",
      "\n",
      "Dataset type: data, additional samples: 4516\n",
      " Model    0 | Train Loss: 0.0184 | accs: 0.0400\n",
      " Model  282 | Train Loss: 0.0223 | accs: 0.1006\n",
      " Model  752 | Train Loss: 0.0195 | accs: 0.2026\n",
      " Model 1693 | Train Loss: 0.0125 | accs: 0.4020\n",
      " Model 2634 | Train Loss: 0.0097 | accs: 0.6018\n",
      " Model 3104 | Train Loss: 0.0088 | accs: 0.7022\n",
      " Model 3575 | Train Loss: 0.0073 | accs: 0.8622\n",
      " Model 4516 | Train Loss: 0.0048 | accs: 1.0000\n",
      " Model 5457 | Train Loss: 0.0033 | accs: 1.0000\n",
      " Model 6398 | Train Loss: 0.0022 | accs: 1.0000\n",
      "\n",
      "Dataset type: data, additional samples: 5457\n",
      " Model    0 | Train Loss: 0.0186 | accs: 0.0333\n",
      " Model  282 | Train Loss: 0.0227 | accs: 0.0838\n",
      " Model  752 | Train Loss: 0.0202 | accs: 0.1695\n",
      " Model 1693 | Train Loss: 0.0134 | accs: 0.3353\n",
      " Model 2634 | Train Loss: 0.0105 | accs: 0.5026\n",
      " Model 3104 | Train Loss: 0.0096 | accs: 0.5883\n",
      " Model 3575 | Train Loss: 0.0080 | accs: 0.7802\n",
      " Model 4516 | Train Loss: 0.0052 | accs: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model 5457 | Train Loss: 0.0033 | accs: 1.0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model 6398 | Train Loss: 0.0022 | accs: 1.0000\n",
      "\n",
      "Dataset type: data, additional samples: 6398\n",
      " Model    0 | Train Loss: 0.0187 | accs: 0.0288\n",
      " Model  282 | Train Loss: 0.0230 | accs: 0.0723\n",
      " Model  752 | Train Loss: 0.0208 | accs: 0.1458\n",
      " Model 1693 | Train Loss: 0.0141 | accs: 0.2876\n",
      " Model 2634 | Train Loss: 0.0111 | accs: 0.4323\n",
      " Model 3104 | Train Loss: 0.0102 | accs: 0.5056\n",
      " Model 3575 | Train Loss: 0.0084 | accs: 0.7173\n",
      " Model 4516 | Train Loss: 0.0055 | accs: 0.9998\n",
      " Model 5457 | Train Loss: 0.0035 | accs: 1.0000\n",
      " Model 6398 | Train Loss: 0.0022 | accs: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Summary of Training Results\n",
    "# ====================================\n",
    "print(\"=== True Generalization ===\")\n",
    "for model_data in all_models:\n",
    "    model = model_data[\"model\"]\n",
    "    additional_data = model_data[\"additional_data\"]\n",
    "\n",
    "    test_loss, test_metrics = evaluate(\n",
    "        model=model,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        loss_fn=loss_fn,\n",
    "        metrics=other_metrics\n",
    "    )\n",
    "\n",
    "    metrics_str = \" | \".join([f\"{name}: {val:.4f}\" for name, val in test_metrics.items()])\n",
    "    print(\n",
    "        f\"{additional_data:>4} samples | \"\n",
    "        f\"Test Loss: {test_loss:.4f}\" + (f\" | {metrics_str}\" if metrics_str else \"\")\n",
    "    )\n",
    "\n",
    "print(\"\\n=== Model Diagnostics by Training Data ===\")\n",
    "for additional_data in dataset_quantities:\n",
    "    # Build dataset with this many additional samples\n",
    "    x_train = torch.cat([x_base_train, x_additional[:additional_data]], dim=0)\n",
    "    y_train = torch.cat([y_base_train, y_additional[:additional_data]], dim=0)\n",
    "\n",
    "    print(f\"\\nDataset type: {dataset_type}, additional samples: {additional_data}\")\n",
    "\n",
    "    for model_data in all_models:\n",
    "        model = model_data[\"model\"]\n",
    "        model_additional_data = model_data[\"additional_data\"]\n",
    "\n",
    "        train_loss, train_metrics = evaluate(\n",
    "            model=model,\n",
    "            x_test=x_train,\n",
    "            y_test=y_train,\n",
    "            loss_fn=loss_fn,\n",
    "            metrics=other_metrics\n",
    "        )\n",
    "\n",
    "        metrics_str = \" | \".join([f\"{name}: {val:.4f}\" for name, val in train_metrics.items()])\n",
    "        print(\n",
    "            f\" Model {model_additional_data:>4} | \"\n",
    "            f\"Train Loss: {train_loss:.4f}\" + (f\" | {metrics_str}\" if metrics_str else \"\")\n",
    "        )\n",
    "\n",
    "    # Free memory if large\n",
    "    del x_train, y_train\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d747e684-36dc-4c51-803d-9a42d0f2db29",
   "metadata": {
    "papermill": {
     "duration": 0.004865,
     "end_time": "2025-09-23T18:29:03.044235",
     "exception": false,
     "start_time": "2025-09-23T18:29:03.039370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model + Data Specific Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b2f4a9-2bd1-4d25-b726-3b0023e81698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T18:29:03.055874Z",
     "iopub.status.busy": "2025-09-23T18:29:03.054615Z",
     "iopub.status.idle": "2025-09-23T18:29:03.058128Z",
     "shell.execute_reply": "2025-09-23T18:29:03.058128Z"
    },
    "papermill": {
     "duration": 0.010886,
     "end_time": "2025-09-23T18:29:03.059132",
     "exception": false,
     "start_time": "2025-09-23T18:29:03.048246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_module.verify_model_results(\n",
    "    all_models=all_models,\n",
    "    x_base_train=x_base_train,\n",
    "    y_base_train=y_base_train,\n",
    "    x_additional=x_additional,\n",
    "    y_additional=y_additional,\n",
    "    x_test=x_test,\n",
    "    y_test=y_test,\n",
    "    dataset_quantities=dataset_quantities,\n",
    "    dataset_type=dataset_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91dd774-874f-446e-85f0-79dc55796ee4",
   "metadata": {
    "papermill": {
     "duration": 0.006504,
     "end_time": "2025-09-23T18:29:03.070123",
     "exception": false,
     "start_time": "2025-09-23T18:29:03.063619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32553783-d0ce-4eb8-8514-261dc643ca2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-23T18:29:03.083439Z",
     "iopub.status.busy": "2025-09-23T18:29:03.083439Z",
     "iopub.status.idle": "2025-09-23T18:29:03.126192Z",
     "shell.execute_reply": "2025-09-23T18:29:03.126192Z"
    },
    "papermill": {
     "duration": 0.05102,
     "end_time": "2025-09-23T18:29:03.127198",
     "exception": false,
     "start_time": "2025-09-23T18:29:03.076178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset saved to models_and_data\\dataset.pt\n",
      "Saved dataset to models_and_data/dataset.pt\n",
      "✅ Model saved to models_and_data\\model_additional_0.pt\n",
      "Saved model: models_and_data/model_additional_0.pt\n",
      "✅ Model saved to models_and_data\\model_additional_282.pt\n",
      "Saved model: models_and_data/model_additional_282.pt\n",
      "✅ Model saved to models_and_data\\model_additional_752.pt\n",
      "Saved model: models_and_data/model_additional_752.pt\n",
      "✅ Model saved to models_and_data\\model_additional_1693.pt\n",
      "Saved model: models_and_data/model_additional_1693.pt\n",
      "✅ Model saved to models_and_data\\model_additional_2634.pt\n",
      "Saved model: models_and_data/model_additional_2634.pt\n",
      "✅ Model saved to models_and_data\\model_additional_3104.pt\n",
      "Saved model: models_and_data/model_additional_3104.pt\n",
      "✅ Model saved to models_and_data\\model_additional_3575.pt\n",
      "Saved model: models_and_data/model_additional_3575.pt\n",
      "✅ Model saved to models_and_data\\model_additional_4516.pt\n",
      "Saved model: models_and_data/model_additional_4516.pt\n",
      "✅ Model saved to models_and_data\\model_additional_5457.pt\n",
      "Saved model: models_and_data/model_additional_5457.pt\n",
      "✅ Model saved to models_and_data\\model_additional_6398.pt\n",
      "Saved model: models_and_data/model_additional_6398.pt\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Save Datasets and Models\n",
    "# ====================================\n",
    "output_folder = \"models_and_data\"\n",
    "# Save dataset (Possible to skip)\n",
    "if save_generated_dataset:\n",
    "    save_dataset(\n",
    "        folder=output_folder,\n",
    "        filename=\"dataset.pt\",\n",
    "        x_base_train=x_base_train,\n",
    "        y_base_train=y_base_train,\n",
    "        x_additional=x_additional,\n",
    "        y_additional=y_additional,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        dataset_quantities=dataset_quantities,\n",
    "        dataset_type=dataset_type,\n",
    "    )\n",
    "    print(f\"Saved dataset to {output_folder}/dataset.pt\")\n",
    "\n",
    "# Save trained models\n",
    "if save_generated_models:\n",
    "    for model_data in all_models:\n",
    "        filename = f\"model_additional_{model_data['additional_data']}.pt\"\n",
    "        save_model(\n",
    "            folder=output_folder,\n",
    "            filename=filename,\n",
    "            model=model_data[\"model\"],\n",
    "            train_loss=model_data[\"train_loss\"],\n",
    "            train_accs=model_data[\"train_accs\"],\n",
    "            test_loss=model_data[\"test_loss\"],\n",
    "            test_accs=model_data[\"test_accs\"],\n",
    "            additional_data=model_data[\"additional_data\"],\n",
    "            dataset_type=model_data[\"dataset_type\"],\n",
    "        )\n",
    "        print(f\"Saved model: {output_folder}/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530ae37-14b3-4d87-a88f-b8c868788a2c",
   "metadata": {
    "papermill": {
     "duration": 0.003245,
     "end_time": "2025-09-23T18:29:03.134493",
     "exception": false,
     "start_time": "2025-09-23T18:29:03.131248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diffusion-env)",
   "language": "python",
   "name": "diffusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 45.964945,
   "end_time": "2025-09-23T18:29:04.024218",
   "environment_variables": {},
   "exception": null,
   "input_path": "Train Low Test Models.ipynb",
   "output_path": "Train Low Test Models.ipynb",
   "parameters": {},
   "start_time": "2025-09-23T18:28:18.059273",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}