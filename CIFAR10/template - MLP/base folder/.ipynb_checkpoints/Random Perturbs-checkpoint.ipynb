{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4494701a-38ed-4662-8e6b-66b8e14fcadf",
   "metadata": {},
   "source": [
    "# Random Perturbations\n",
    "\n",
    "Streamlined notebook for evaluating random perturbations on saved models and datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243f018-2c18-476a-82a6-10cdbce9e963",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b91824-82ff-4a5a-9a9c-434fa49310c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Third-party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Local package imports\n",
    "from minima_volume.perturb_funcs import ( analyze_wiggles_metrics )\n",
    "\n",
    "from minima_volume.dataset_funcs import (\n",
    "    load_dataset,\n",
    "    load_model,\n",
    "    load_models_and_data,\n",
    "    prepare_datasets,\n",
    "    tensor_to_list,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d7d91-a84f-4acd-9ea4-ce6c8b45ed39",
   "metadata": {},
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb0358d-193d-4228-8a73-baad9a52d6e0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Perturbation Configuration\n",
    "perturbation_seed = 1\n",
    "num_directions = 50\n",
    "N = 100\n",
    "x = np.linspace(0, 1, N)\n",
    "coefficients = x**2\n",
    "\n",
    "# Other Configuration\n",
    "dataset_quantities = [0, 500-50, 2000 - 50, 5000 - 50, 20000 - 50, 50000 - 50]\n",
    "base_output_dir = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6af0fc-d0a3-4793-8ca0-33c9461c6777",
   "metadata": {},
   "source": [
    "## Model + Dataset Specific Code\n",
    "\n",
    "This is for model and dataset specific code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "389d62b5-59f9-43ff-9c59-8e57e3d39f84",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mCIFAR10_model_data\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodel_module\u001b[39;00m  \u001b[38;5;66;03m# <- your new CIFAR-10 module\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Generate dataset\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m x_base, y_base, x_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# CIFAR-10 MLP initialization parameters\u001b[39;00m\n\u001b[0;32m     10\u001b[0m hidden_dims \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m]  \u001b[38;5;66;03m# larger hidden layers due to higher input dimension\u001b[39;00m\n",
      "File \u001b[1;32mL:\\Programming\\ARC\\minima_volume_project\\CIFAR-10\\example - base\\base folder\\CIFAR10_model_data.py:41\u001b[0m, in \u001b[0;36mget_dataset\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[0;32m     40\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mCIFAR10(data_dir, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m---> 41\u001b[0m test_dataset  \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Convert entire dataset into big tensors\u001b[39;00m\n\u001b[0;32m     44\u001b[0m train_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([img \u001b[38;5;28;01mfor\u001b[39;00m img, _ \u001b[38;5;129;01min\u001b[39;00m train_dataset])   \u001b[38;5;66;03m# shape: [50000, 3, 32, 32]\u001b[39;00m\n",
      "File \u001b[1;32mL:\\Programming\\diffusion-env\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:68\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_integrity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain:\n",
      "File \u001b[1;32mL:\\Programming\\diffusion-env\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:132\u001b[0m, in \u001b[0;36mCIFAR10._check_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename, md5 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_list \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_list:\n\u001b[0;32m    131\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_folder, filename)\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcheck_integrity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mL:\\Programming\\diffusion-env\\Lib\\site-packages\\torchvision\\datasets\\utils.py:58\u001b[0m, in \u001b[0;36mcheck_integrity\u001b[1;34m(fpath, md5)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m md5 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_md5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mL:\\Programming\\diffusion-env\\Lib\\site-packages\\torchvision\\datasets\\utils.py:50\u001b[0m, in \u001b[0;36mcheck_md5\u001b[1;34m(fpath, md5, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_md5\u001b[39m(fpath: Union[\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath], md5: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m md5 \u001b[38;5;241m==\u001b[39m \u001b[43mcalculate_md5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mL:\\Programming\\diffusion-env\\Lib\\site-packages\\torchvision\\datasets\\utils.py:45\u001b[0m, in \u001b[0;36mcalculate_md5\u001b[1;34m(fpath, chunk_size)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m chunk \u001b[38;5;241m:=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(chunk_size):\n\u001b[1;32m---> 45\u001b[0m         \u001b[43mmd5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m md5\u001b[38;5;241m.\u001b[39mhexdigest()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# User specifies the CIFAR-10 model module name\n",
    "import CIFAR10_model_data as model_module  # <- your new CIFAR-10 module\n",
    "\n",
    "# Generate dataset\n",
    "x_base, y_base, x_test, y_test = model_module.get_dataset(\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# CIFAR-10 MLP initialization parameters\n",
    "hidden_dims = [512, 256]  # larger hidden layers due to higher input dimension\n",
    "\n",
    "# Grab model\n",
    "model_template = model_module.get_model(hidden_dims=hidden_dims, device=device, seed=0)\n",
    "\n",
    "# Grab loss and metrics\n",
    "loss_fn = model_module.get_loss_fn()\n",
    "other_metrics = model_module.get_additional_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b444f632-4ed7-4f3d-9f18-19a6cedabed8",
   "metadata": {},
   "source": [
    "## Loading Model and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dff34d-5a53-49d0-a3df-d1306cecd722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# Load Trained Models and Dataset\n",
    "# ====================================\n",
    "target_dir = \"models_and_data\"  # relative path\n",
    "loaded_models, loaded_model_data, loaded_dataset = load_models_and_data(\n",
    "    model_template=model_template,\n",
    "    target_dir=target_dir,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Dataset Info\n",
    "dataset_type = loaded_dataset['dataset_type']\n",
    "print(f\"Dataset type: {dataset_type}\")\n",
    "print(f\"Dataset quantities: {loaded_dataset['dataset_quantities']}\")\n",
    "\n",
    "print(\"\\nTensor shapes:\")\n",
    "for key in [\"x_base_train\", \"y_base_train\", \"x_additional\", \"y_additional\", \"x_test\", \"y_test\"]:\n",
    "    shape = getattr(loaded_dataset[key], \"shape\", None)\n",
    "    print(f\"  {key}: {shape if shape is not None else 'None'}\")\n",
    "\n",
    "# Reconstruct trained_model dicts safely.\n",
    "# If the loss or accuracy or additional metrics happen to be\n",
    "# tensors, they get safely converted to lists.\n",
    "all_models = [\n",
    "    {\n",
    "        \"model\": model,\n",
    "        **{\n",
    "            k: tensor_to_list(model_data[k], key_path=k)\n",
    "            for k in [\"train_loss\", \"train_accs\", \"test_loss\", \"test_accs\", \"additional_data\", \"dataset_type\"]\n",
    "        },\n",
    "    }\n",
    "    for model, model_data in zip(loaded_models, loaded_model_data)\n",
    "]\n",
    "print(f\"Reconstructed {len(all_models)} trained models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e6661-c42d-43b7-9ddd-291d56ff910f",
   "metadata": {},
   "source": [
    "## Perturbations\n",
    "\n",
    "Using the saved datasets, we perform model perturbations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b83dd-2850-45f2-b9b3-e7ead77b93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "x_base_train = loaded_dataset['x_base_train'].to(device)\n",
    "y_base_train = loaded_dataset['y_base_train'].to(device)\n",
    "x_additional = loaded_dataset['x_additional'].to(device)\n",
    "y_additional = loaded_dataset['y_additional'].to(device)\n",
    "x_test = loaded_dataset['x_test'].to(device)\n",
    "y_test = loaded_dataset['y_test'].to(device)\n",
    "\n",
    "# Loss function and metrics already grabbed from the model module\n",
    "analyze_wiggles_metrics(\n",
    "    model_list = all_models, \n",
    "    x_base_train = x_base_train,\n",
    "    y_base_train = y_base_train, \n",
    "    x_additional = x_additional,\n",
    "    y_additional = y_additional,\n",
    "    x_test = x_test,\n",
    "    y_test = y_test, \n",
    "    dataset_quantities = dataset_quantities, \n",
    "    dataset_type = dataset_type, \n",
    "    metrics = {\"loss\": loss_fn, **other_metrics}, \n",
    "    coefficients = coefficients,\n",
    "    num_directions = num_directions,\n",
    "    perturbation_seed = perturbation_seed,\n",
    "    base_output_dir = base_output_dir,\n",
    "    device = device,  # can be set to GPU if needed\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\" Our saved results are structured as follows:\n",
    "wiggle_results: List of dictionaries containing wiggle test results\n",
    "Each dictionary is of the form\n",
    "{\n",
    "'loss':\n",
    "'coefficients':\n",
    "'accs':\n",
    "'perturbation_seed':\n",
    "'perturbation_norm':\n",
    "}\n",
    "model: PyTorch model used in analysis (state_dict will be saved)\n",
    "output_dir: Directory to save results (default: \"imgs/swiss/random_dirs\")\n",
    "filename: Name of output file (default: \"random_directions.npz\")\n",
    "**kwargs: Additional key-value pairs to be saved in the output file\n",
    "Typically:\n",
    "'additional_data':\n",
    "'model_trained_data':\n",
    "'dataset_type':\n",
    "'base_dataset_size': \n",
    "'test_loss':\n",
    "'test_accs':\n",
    "'num_params':\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530ae37-14b3-4d87-a88f-b8c868788a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diffusion-env)",
   "language": "python",
   "name": "diffusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
