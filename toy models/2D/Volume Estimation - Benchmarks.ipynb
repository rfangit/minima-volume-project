{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abece012-7983-4c71-b629-3a8884fa7401",
   "metadata": {},
   "source": [
    "# Benchmarks\n",
    "\n",
    "Our code right now takes a while to run for a large number of directions. We'd like to understand what parts take the longest to run, so we can speed it up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3134e97-084c-499a-befc-6cc24c64836d",
   "metadata": {},
   "source": [
    "### Loss landscape and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089d6c7a-4146-435b-bd92-22db5e68e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "class LossLandscape:\n",
    "    def __init__(self, \n",
    "                 minima_sharp_loc=-1.0, \n",
    "                 minima_wide_loc=1.0,\n",
    "                 sharp_width=0.1,\n",
    "                 wide_width=0.2,\n",
    "                 amplitude=1.0,\n",
    "                 baseline=1.0):\n",
    "        \"\"\"\n",
    "        Initialize a customizable loss landscape with two minima.\n",
    "        \"\"\"\n",
    "        self.minima_sharp_loc = minima_sharp_loc\n",
    "        self.minima_wide_loc = minima_wide_loc\n",
    "        self.sharp_width = sharp_width\n",
    "        self.wide_width = wide_width\n",
    "        self.amplitude = amplitude\n",
    "        self.baseline = baseline\n",
    "        \n",
    "    def get_minima_parameters(self):\n",
    "        \"\"\"Return the key parameters defining the minima\"\"\"\n",
    "        return {\n",
    "            'minima_sharp_loc': self.minima_sharp_loc,\n",
    "            'minima_wide_loc': self.minima_wide_loc,\n",
    "            'sharp_width': self.sharp_width,\n",
    "            'wide_width': self.wide_width\n",
    "        }\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\"Compute the loss at point(s) x\"\"\"\n",
    "        gaussian_sharp = self.amplitude * torch.exp(\n",
    "            -0.5 * ((x - self.minima_sharp_loc) / self.sharp_width)**2\n",
    "        )\n",
    "        gaussian_wide = self.amplitude * torch.exp(\n",
    "            -0.5 * ((x - self.minima_wide_loc) / self.wide_width)**2\n",
    "        )\n",
    "        return self.baseline - gaussian_sharp - gaussian_wide\n",
    "    \n",
    "    def visualize(self, x_range=(-2, 2), num_points=500):\n",
    "        \"\"\"Visualize the loss landscape\"\"\"\n",
    "        x = torch.linspace(x_range[0], x_range[1], num_points)\n",
    "        loss = self(x)\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(x.numpy(), loss.numpy())\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss Landscape')\n",
    "        \n",
    "        plt.axvline(x=self.minima_sharp_loc, color='r', \n",
    "                   linestyle='--', alpha=0.3, label='Sharp minimum')\n",
    "        plt.axvline(x=self.minima_wide_loc, color='b', \n",
    "                   linestyle='--', alpha=0.3, label='Wide minimum')\n",
    "        \n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def random_parameter_search(self, dim: int, num_samples: int = 10000, upper = 10, low = -10):\n",
    "        \"\"\"\n",
    "        Perform random parameter search using the class's minima parameters\n",
    "        \n",
    "        Args:\n",
    "            dim: Dimension of parameter space\n",
    "            num_samples: Number of random samples to generate\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (sharp_count, wide_count, samples)\n",
    "        \"\"\"\n",
    "        minima_sharp_count = 0\n",
    "        minima_wide_count = 0\n",
    "        samples = []\n",
    "        \n",
    "        for _ in range(num_samples):\n",
    "            params = np.random.uniform(low=low, high=upper, size=dim)\n",
    "            product = np.prod(params)\n",
    "            samples.append(product)\n",
    "            \n",
    "            if abs(product - self.minima_sharp_loc) < self.sharp_width:\n",
    "                minima_sharp_count += 1\n",
    "            if abs(product - self.minima_wide_loc) < self.wide_width:\n",
    "                minima_wide_count += 1\n",
    "        \n",
    "        return minima_sharp_count, minima_wide_count, samples\n",
    "        \n",
    "class NParameterModel(torch.nn.Module):\n",
    "    def __init__(self, initial_values: List[float]):\n",
    "        super().__init__()\n",
    "        # Create N parameters from the initial values\n",
    "        self.params = torch.nn.ParameterList([\n",
    "            torch.nn.Parameter(torch.tensor([val], dtype=torch.float32))\n",
    "            for val in initial_values\n",
    "        ])\n",
    "    \n",
    "    def forward(self):\n",
    "        # Compute product of all parameters\n",
    "        x = torch.prod(torch.stack([p for p in self.params]))\n",
    "        return x\n",
    "\n",
    "    def get_parameter_values(self):\n",
    "        return [p.item() for p in self.params]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc02c0d-1de5-41a1-9c1c-35f59ea706c8",
   "metadata": {},
   "source": [
    "### Perturbation Functions\n",
    "\n",
    "These are the likely bottlenecks that we want to benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41023f16-f19e-4948-a52a-365df6763830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our existing funcs\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Add parent directory to sys.path\n",
    "parent_dir = Path.cwd().parent\n",
    "sys.path.append(str(parent_dir))\n",
    "# Import modules\n",
    "from perturb_simple import (\n",
    "    generate_random_perturbations,\n",
    ")\n",
    "\n",
    "# Class for implementing perturbations\n",
    "class ModelPerturber:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.original_state = {n: p.detach().clone() \n",
    "                              for n, p in model.named_parameters()}\n",
    "    \n",
    "    def apply_perturbation(self, perturbation_dict):\n",
    "        \"\"\"\n",
    "        Apply custom perturbations to model weights\n",
    "        perturbation_dict: {param_name: tensor_with_same_shape}\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if name in perturbation_dict:\n",
    "                    param.add_(perturbation_dict[name])\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Revert to original weights\"\"\"\n",
    "        with torch.no_grad():\n",
    "            for name, param in self.model.named_parameters():\n",
    "                param.copy_(self.original_state[name])\n",
    "\n",
    "def wiggle_simple(simple_model, loss_fn, perturbation_direction, coefficients):\n",
    "    \"\"\"\n",
    "    Evaluates the model with given perturbation coefficients applied to each direction.\n",
    "    \n",
    "    Args:\n",
    "        simple_model: A simple model that returns the parameter value directly.\n",
    "        loss_fn: the loss for that parameter value\n",
    "        perturbations: List of dictionaries [{param_name: tensor}] of what the specific perturbation does to each weight\n",
    "        coefficients: List of coefficients to apply to each perturbation direction\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "        - 'losses': array of losses for each perturbation\n",
    "        - 'coefficients': array of coefficients used (same as input)\n",
    "        - 'perturbations': list of perturbation directions used\n",
    "    \"\"\"\n",
    "    perturber = ModelPerturber(simple_model)\n",
    "    losses = []\n",
    "\n",
    "    for i, coeff in enumerate(coefficients):\n",
    "        perturbation = {\n",
    "            name: perturbation_direction[name] * coeff\n",
    "            for name in perturbation_direction\n",
    "        }\n",
    "\n",
    "        perturber.apply_perturbation(perturbation)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = simple_model()\n",
    "            loss = loss_fn(x)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "        perturber.reset()\n",
    "\n",
    "    return {\n",
    "        'losses': np.array(losses),\n",
    "        'coefficients': coefficients,\n",
    "        'perturbations': perturbation_direction,\n",
    "    }\n",
    "\n",
    "def wiggle_multiple_directions(\n",
    "    model,\n",
    "    loss_fn,\n",
    "    perturbation_directions,  # List of {param_name: tensor} dicts\n",
    "    coefficients,             # List of coefficients (same for all directions)\n",
    "    verbose=False,            # Print progress\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluates wiggle_simple along a list of perturbations\n",
    "    \n",
    "    Returns:\n",
    "        List of results (same format as wiggle_simple), one per direction.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, direction in enumerate(perturbation_directions):\n",
    "        if verbose:\n",
    "            print(f\"Evaluating direction {i+1}/{len(perturbation_directions)}...\")\n",
    "        \n",
    "        # Run wiggle_simple for this direction\n",
    "        result = wiggle_simple(\n",
    "            simple_model=model,\n",
    "            loss_fn=loss_fn,\n",
    "            perturbation_direction=direction,\n",
    "            coefficients=coefficients,\n",
    "        )\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def loss_threshold_crossing(wiggle_results, loss_threshold):\n",
    "    \"\"\"\n",
    "    Find the radius r at which each direction first crosses the loss threshold.\n",
    "    \n",
    "    Args:\n",
    "        wiggle_results: List of result dicts containing 'losses' and 'coefficients'\n",
    "        Access is in the form wiggle_results[list_index]['losses'][loss for specific coeff]\n",
    "        loss_threshold: Loss value threshold to search for\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (r_values, valid_directions) where:\n",
    "        - r_values: List of radii where threshold was crossed (empty if never crossed)\n",
    "        - valid_directions: Boolean mask indicating which directions crossed threshold\n",
    "    \"\"\"\n",
    "    r_values = []\n",
    "    valid_directions = []\n",
    "    \n",
    "    for result in wiggle_results:\n",
    "        coefficients = result['coefficients']\n",
    "        losses = result['losses']\n",
    "        crossed = False\n",
    "        \n",
    "        # Find first point where loss exceeds threshold\n",
    "        for i in range(len(losses)):\n",
    "            if losses[i] > loss_threshold:\n",
    "                if i > 0:  # Only record if we have a valid previous point\n",
    "                    r_values.append(abs(coefficients[i-1]))\n",
    "                    crossed = True\n",
    "                break\n",
    "                \n",
    "        valid_directions.append(crossed)\n",
    "        if crossed == False: #still append something, just for completeness, even if it's an underestimate\n",
    "            r_values.append(abs(coefficients[len(losses) - 1]))\n",
    "    \n",
    "    return r_values, valid_directions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7621481-a444-49ec-85b0-68b6452e76cb",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "Here, you can run the experiment. Change experimental parameters at will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52eb53a8-0a0b-4af9-8447-aa059e702683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our loss landscape\n",
    "minima_sharp_loc=-1.0\n",
    "minima_wide_loc=0.5\n",
    "sharp_width=0.1\n",
    "wide_width=0.2\n",
    "loss_fn = LossLandscape(minima_sharp_loc=minima_sharp_loc, \n",
    "                 minima_wide_loc=minima_wide_loc,\n",
    "                 sharp_width=sharp_width,\n",
    "                 wide_width=wide_width)\n",
    "\n",
    "# The loss is 1 - gaussian_sharp, which is 0.3935\n",
    "loss_threshold = 0.3935\n",
    "\n",
    "# A family of models, located at the wide minima, with a variety of scale factors\n",
    "scale_factors = [1.0]\n",
    "model_family = [NParameterModel([np.sqrt(minima_wide_loc)*scale, np.sqrt(minima_wide_loc)/scale]) for scale in scale_factors]\n",
    "\n",
    "# Maximum number of perturbation directions\n",
    "num_perturb_directions = 50\n",
    "seed = 10\n",
    "torch.manual_seed(seed)\n",
    "random_perturb_vectors = generate_random_perturbations(model_family[0], n = num_perturb_directions)\n",
    "\n",
    "# Coefficients to sample\n",
    "N = 1001\n",
    "coefficients = np.linspace(0, 10, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266e96a-6ce3-433e-9ef7-e91bd97d1f00",
   "metadata": {},
   "source": [
    "# Actual Code\n",
    "\n",
    "Here is the actual code, which we want to benchmark. First, which check how much wiggle_multiple and loss_threshold take. We suspect that wiggle_multiple is the real botteneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "130f499a-7faa-4645-b7f6-af4e20412d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing model 1/1\n",
      "wiggle_multiple_directions took 12.7266 seconds\n",
      "loss_threshold_crossing took 0.0000 seconds\n",
      "Done random!\n",
      "Finished computing radii!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Initialize storage for r values\n",
    "random_r_array = [[None] for _ in range(len(model_family))]\n",
    "\n",
    "# The minima and the width\n",
    "a = minima_wide_loc\n",
    "w = wide_width\n",
    "\n",
    "# Go through each member of the model family\n",
    "for model_idx, model in enumerate(model_family):\n",
    "    print(f\"\\nProcessing model {model_idx + 1}/{len(model_family)}\")\n",
    "\n",
    "    ################ RANDOM ################\n",
    "    ## Numeric random r\n",
    "    \n",
    "    # Start timer for wiggle_multiple_directions\n",
    "    start_wiggle = time.time()\n",
    "    \n",
    "    random_loss_results = wiggle_multiple_directions(\n",
    "        model=model_family[model_idx],\n",
    "        loss_fn=loss_fn,\n",
    "        perturbation_directions=random_perturb_vectors,\n",
    "        coefficients=coefficients,\n",
    "        #verbose = True,\n",
    "    )\n",
    "    \n",
    "    # End timer for wiggle_multiple_directions\n",
    "    end_wiggle = time.time()\n",
    "    wiggle_time = end_wiggle - start_wiggle\n",
    "    print(f\"wiggle_multiple_directions took {wiggle_time:.4f} seconds\")\n",
    "    \n",
    "    # Start timer for loss_threshold_crossing\n",
    "    start_threshold = time.time()\n",
    "    \n",
    "    random_r_values, valid_directions = loss_threshold_crossing(random_loss_results, loss_threshold)\n",
    "    \n",
    "    # End timer for loss_threshold_crossing\n",
    "    end_threshold = time.time()\n",
    "    threshold_time = end_threshold - start_threshold\n",
    "    print(f\"loss_threshold_crossing took {threshold_time:.4f} seconds\")\n",
    "    \n",
    "    # Check for invalid directions\n",
    "    if not all(valid_directions):\n",
    "        invalid_count = len([v for v in valid_directions if not v])\n",
    "        print(f\"Random Warning: {invalid_count}/{len(valid_directions)} directions failed threshold\")\n",
    "    \n",
    "    # Store r_values\n",
    "    random_r_array[model_idx] = random_r_values\n",
    "    print(\"Done random!\")\n",
    "\n",
    "print(\"Finished computing radii!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce4e3e-d520-44f4-871e-dd3505376282",
   "metadata": {},
   "source": [
    "So as expected, wiggle multiple takes the majority of the time. It takes nearly 1/4 of a second per direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1fac65-662d-42bb-be74-c4aeabb8ed2f",
   "metadata": {},
   "source": [
    "### Wiggle Multiple Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c39190fc-9aff-4bcb-aeaa-da717fe49eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiggle_simple_benchmark(simple_model, loss_fn, perturbation_direction, coefficients):\n",
    "    \"\"\"\n",
    "    Evaluates the model with given perturbation coefficients applied to each direction.\n",
    "    \"\"\"\n",
    "    perturber = ModelPerturber(simple_model)\n",
    "    losses = []\n",
    "    \n",
    "    # Track time per coefficient\n",
    "    total_time = 0.0\n",
    "    apply_time = 0.0\n",
    "    loss_time = 0.0\n",
    "    reset_time = 0.0\n",
    "\n",
    "    for i, coeff in enumerate(coefficients):\n",
    "        # Time perturbation application\n",
    "        start_apply = time.time()\n",
    "        perturbation = {\n",
    "            name: perturbation_direction[name] * coeff\n",
    "            for name in perturbation_direction\n",
    "        }\n",
    "        perturber.apply_perturbation(perturbation)\n",
    "        apply_time += time.time() - start_apply\n",
    "\n",
    "        # Time loss computation\n",
    "        start_loss = time.time()\n",
    "        with torch.no_grad():\n",
    "            x = simple_model()\n",
    "            loss = loss_fn(x)\n",
    "            losses.append(loss.item())\n",
    "        loss_time += time.time() - start_loss\n",
    "\n",
    "        # Time reset\n",
    "        start_reset = time.time()\n",
    "        perturber.reset()\n",
    "        reset_time += time.time() - start_reset\n",
    "\n",
    "    total_time = apply_time + loss_time + reset_time\n",
    "    \n",
    "    # Print timing breakdown (per direction)\n",
    "    print(f\"\\nPer-coefficient breakdown for direction:\")\n",
    "    print(f\"  - Apply perturbation: {apply_time:.4f}s ({100 * apply_time / total_time:.1f}%)\")\n",
    "    print(f\"  - Loss computation:   {loss_time:.4f}s ({100 * loss_time / total_time:.1f}%)\")\n",
    "    print(f\"  - Reset:              {reset_time:.4f}s ({100 * reset_time / total_time:.1f}%)\")\n",
    "    print(f\"Total time per direction: {total_time:.4f}s\")\n",
    "\n",
    "    return {\n",
    "        'losses': np.array(losses),\n",
    "        'coefficients': coefficients,\n",
    "        'perturbations': perturbation_direction,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8204148-7bab-454f-a80e-f7d2b3275491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-coefficient breakdown for direction:\n",
      "  - Apply perturbation: 0.0354s (18.8%)\n",
      "  - Loss computation:   0.1344s (71.6%)\n",
      "  - Reset:              0.0180s (9.6%)\n",
      "Total time per direction: 0.1878s\n"
     ]
    }
   ],
   "source": [
    "random_loss_results = wiggle_simple_benchmark(\n",
    "        simple_model=model_family[model_idx],\n",
    "        loss_fn=loss_fn,\n",
    "        perturbation_direction=random_perturb_vectors[0],\n",
    "        coefficients=coefficients,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c41747-195b-4991-be32-cf20ff24fbfb",
   "metadata": {},
   "source": [
    "The majority of the time taken is in the loss computation. This is dependent on our algorithm and can't be sped up. Perhaps this speed benchmarking is premature, given that our system is so trivial (2 parameters) and the results may not be reflective of actual use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2def1-418d-47f4-a135-f5fc8c2a3d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diffusion-env)",
   "language": "python",
   "name": "diffusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
