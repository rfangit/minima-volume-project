{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abece012-7983-4c71-b629-3a8884fa7401",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Here, we compare analytic results for volume estimation, with the numeric results from using circular and random vector perturbations. We want to confirm the results are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3134e97-084c-499a-befc-6cc24c64836d",
   "metadata": {},
   "source": [
    "### Base\n",
    "\n",
    "Loss landscape and model definition. (Not initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089d6c7a-4146-435b-bd92-22db5e68e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "class LossLandscape:\n",
    "    def __init__(self, \n",
    "                 minima_sharp_loc=-1.0, \n",
    "                 minima_wide_loc=1.0,\n",
    "                 sharp_width=0.1,\n",
    "                 wide_width=0.2,\n",
    "                 amplitude=1.0,\n",
    "                 baseline=1.0):\n",
    "        \"\"\"\n",
    "        Initialize a customizable loss landscape with two minima.\n",
    "        \"\"\"\n",
    "        self.minima_sharp_loc = minima_sharp_loc\n",
    "        self.minima_wide_loc = minima_wide_loc\n",
    "        self.sharp_width = sharp_width\n",
    "        self.wide_width = wide_width\n",
    "        self.amplitude = amplitude\n",
    "        self.baseline = baseline\n",
    "        \n",
    "    def get_minima_parameters(self):\n",
    "        \"\"\"Return the key parameters defining the minima\"\"\"\n",
    "        return {\n",
    "            'minima_sharp_loc': self.minima_sharp_loc,\n",
    "            'minima_wide_loc': self.minima_wide_loc,\n",
    "            'sharp_width': self.sharp_width,\n",
    "            'wide_width': self.wide_width\n",
    "        }\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\"Compute the loss at point(s) x\"\"\"\n",
    "        gaussian_sharp = self.amplitude * torch.exp(\n",
    "            -0.5 * ((x - self.minima_sharp_loc) / self.sharp_width)**2\n",
    "        )\n",
    "        gaussian_wide = self.amplitude * torch.exp(\n",
    "            -0.5 * ((x - self.minima_wide_loc) / self.wide_width)**2\n",
    "        )\n",
    "        return self.baseline - gaussian_sharp - gaussian_wide\n",
    "    \n",
    "    def visualize(self, x_range=(-2, 2), num_points=500):\n",
    "        \"\"\"Visualize the loss landscape\"\"\"\n",
    "        x = torch.linspace(x_range[0], x_range[1], num_points)\n",
    "        loss = self(x)\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(x.numpy(), loss.numpy())\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss Landscape')\n",
    "        \n",
    "        plt.axvline(x=self.minima_sharp_loc, color='r', \n",
    "                   linestyle='--', alpha=0.3, label='Sharp minimum')\n",
    "        plt.axvline(x=self.minima_wide_loc, color='b', \n",
    "                   linestyle='--', alpha=0.3, label='Wide minimum')\n",
    "        \n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def random_parameter_search(self, dim: int, num_samples: int = 10000, upper = 10, low = -10):\n",
    "        \"\"\"\n",
    "        Perform random parameter search using the class's minima parameters\n",
    "        \n",
    "        Args:\n",
    "            dim: Dimension of parameter space\n",
    "            num_samples: Number of random samples to generate\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (sharp_count, wide_count, samples)\n",
    "        \"\"\"\n",
    "        minima_sharp_count = 0\n",
    "        minima_wide_count = 0\n",
    "        samples = []\n",
    "        \n",
    "        for _ in range(num_samples):\n",
    "            params = np.random.uniform(low=low, high=upper, size=dim)\n",
    "            product = np.prod(params)\n",
    "            samples.append(product)\n",
    "            \n",
    "            if abs(product - self.minima_sharp_loc) < self.sharp_width:\n",
    "                minima_sharp_count += 1\n",
    "            if abs(product - self.minima_wide_loc) < self.wide_width:\n",
    "                minima_wide_count += 1\n",
    "        \n",
    "        return minima_sharp_count, minima_wide_count, samples\n",
    "        \n",
    "class NParameterModel(torch.nn.Module):\n",
    "    def __init__(self, initial_values: List[float]):\n",
    "        super().__init__()\n",
    "        # Create N parameters from the initial values\n",
    "        self.params = torch.nn.ParameterList([\n",
    "            torch.nn.Parameter(torch.tensor([val], dtype=torch.float32))\n",
    "            for val in initial_values\n",
    "        ])\n",
    "    \n",
    "    def forward(self):\n",
    "        # Compute product of all parameters\n",
    "        x = torch.prod(torch.stack([p for p in self.params]))\n",
    "        return x\n",
    "\n",
    "    def get_parameter_values(self):\n",
    "        return [p.item() for p in self.params]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc02c0d-1de5-41a1-9c1c-35f59ea706c8",
   "metadata": {},
   "source": [
    "### Perturbation Functions\n",
    "\n",
    "We import our perturbation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41023f16-f19e-4948-a52a-365df6763830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our existing funcs\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Add parent directory to sys.path\n",
    "parent_dir = Path.cwd().parent\n",
    "sys.path.append(str(parent_dir))\n",
    "# Import modules\n",
    "from perturb_simple import (\n",
    "    generate_random_perturbations,\n",
    "    wiggle_multiple_directions,\n",
    "    loss_threshold_crossing,\n",
    ")\n",
    "\n",
    "from visualize_2d import (\n",
    "    plot_parameter_space_with_arrows,\n",
    "    plot_parameter_space_with_polygon,\n",
    ")\n",
    "\n",
    "## In our case, we might also use a generate circular perturbations a lot\n",
    "def generate_circular_perturbations(num_vectors):\n",
    "    \"\"\"\n",
    "    Generate evenly spaced unit vectors around a circle using only PyTorch.\n",
    "    \"\"\"\n",
    "    angles = torch.linspace(0, 2 * torch.pi, num_vectors + 1)[:-1]  # Evenly spaced, exclude duplicate 2π\n",
    "    x = torch.cos(angles)\n",
    "    y = torch.sin(angles)\n",
    "    \n",
    "    return [\n",
    "        {'params.0': x[i].reshape(1), 'params.1': y[i].reshape(1)} \n",
    "        for i in range(num_vectors)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac936e65-d4d8-4472-91a2-a8d853eb87fa",
   "metadata": {},
   "source": [
    "### Calculation Methods\n",
    "\n",
    "We have circular and random perturbations, and for the actual radius calculation we consider a pair of methods - the exact analytical radii, and the numeric radii from our coefficient based approach. The numeric method is in loss_threshold_crossing, while the analytic function is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc061d8-37b0-4bb7-b2af-635e8304913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is code that determines the exact distance from the source point to the edges of the curves\n",
    "def find_r(x, y, a, w, vx, vy):\n",
    "    \"\"\"\n",
    "    Compute the smallest positive r such that (x + r*vx, y + r*vy)\n",
    "    intersects either curve y = (a ± w)/x.\n",
    "    \"\"\"\n",
    "    def solve_quadratic(A, B, C):\n",
    "        # Handle near-zero A (linear case)\n",
    "        if abs(A) < 1e-12:\n",
    "            if abs(B) < 1e-12:\n",
    "                return None\n",
    "            r = -C / B\n",
    "            return r if r > 0 else None\n",
    "\n",
    "        D = B**2 - 4 * A * C\n",
    "        if D < 0:\n",
    "            return None\n",
    "\n",
    "        sqrt_D = np.sqrt(D)\n",
    "        r1 = (-B + sqrt_D) / (2 * A)\n",
    "        r2 = (-B - sqrt_D) / (2 * A)\n",
    "\n",
    "        positive_roots = [r for r in (r1, r2) if r > 0]\n",
    "        return min(positive_roots) if positive_roots else None\n",
    "\n",
    "    # Try both boundaries: a + w and a - w\n",
    "    r_candidates = []\n",
    "    for delta in [+w, -w]:\n",
    "        A = vx * vy\n",
    "        B = x * vy + y * vx\n",
    "        C = x * y - (a + delta)\n",
    "\n",
    "        r = solve_quadratic(A, B, C)\n",
    "        if r is not None:\n",
    "            r_candidates.append(r)\n",
    "\n",
    "    return min(r_candidates) if r_candidates else None\n",
    "\n",
    "# A wrapper that processes a list of perturbation vectors\n",
    "def compute_r_list(origin, a, w, perturb_vectors):\n",
    "    x, y = origin\n",
    "    r_list = []\n",
    "\n",
    "    for vec in perturb_vectors:\n",
    "        vx = vec['params.0'].item()\n",
    "        vy = vec['params.1'].item()\n",
    "        r = find_r(x, y, a, w, vx, vy)\n",
    "        r_list.append(r)\n",
    "\n",
    "    return r_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf57a0d-96ec-41b8-812e-d2c3207c45ea",
   "metadata": {},
   "source": [
    "## Analytical Volume\n",
    "\n",
    "The analytical volume derived from our formulas is\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "V &= 2\\sqrt{2w (a + w)} + 2w \\log \\frac{\\left(1 + \\sqrt{\\frac{w}{a+w}} \\right)}{\\left(1 - \\sqrt{\\frac{w}{a+w}} \\right)} - (a - w)\\log \\frac{\\left(1 + \\sqrt{\\frac{2w}{a + w}} \\right)}{\\left(1 - \\sqrt{\\frac{2w}{a + w}} \\right)}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "where the upper and lower bounds of our loss are given by $(x, \\frac{a \\pm w}{x})$. Note that the velocity from our monte carlo method is\n",
    "\n",
    "$$\n",
    "V = V_{\\text{unit ball, n}} \\int r^n (\\theta) d\\theta\n",
    "$$\n",
    "\n",
    "For $n = 2$, the volume of the unit ball is $\\pi$. Our methods compute the expected value of $r^n$, so we divide our analytic volume by $\\pi$ to have their results match (in theory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7762cd33-6de6-4017-a302-85d31c616ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computed volume is: 0.6788802191114742\n"
     ]
    }
   ],
   "source": [
    "def analytic_volume(a, w):\n",
    "    # First term: 2 * sqrt(2 * w * (a + w))\n",
    "    term1 = 2 * np.sqrt(2 * w * (a + w))\n",
    "    \n",
    "    # Second term: 2w * log[(1 + sqrt(w/(a+w))) / (1 - sqrt(w/(a+w)))]\n",
    "    sqrt_w_over_aw = np.sqrt(w / (a + w))\n",
    "    numerator = 1 + sqrt_w_over_aw\n",
    "    denominator = 1 - sqrt_w_over_aw\n",
    "    term2 = 2 * w * np.log(numerator / denominator)\n",
    "    \n",
    "    # Third term: (a - w) * log[(1 + sqrt(2w/(a+w))) / (1 - sqrt(2w/(a+w)))]\n",
    "    sqrt_2w_over_aw = np.sqrt(2 * w / (a + w))\n",
    "    numerator = 1 + sqrt_2w_over_aw\n",
    "    denominator = 1 - sqrt_2w_over_aw\n",
    "    term3 = (a - w) * np.log(numerator / denominator)\n",
    "    \n",
    "    # Combine all terms\n",
    "    V = term1 + term2 - term3\n",
    "    \n",
    "    return V\n",
    "\n",
    "# Example usage:\n",
    "a = 1.0\n",
    "w = 0.2\n",
    "volume = analytic_volume(a, w)\n",
    "print(f\"The computed volume is: {volume}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04664240-9756-4fb9-bc84-5b57f59d014e",
   "metadata": {},
   "source": [
    "## Saving, Loading, Subset Volume\n",
    "\n",
    "Functions for saving the radii data, loading it, and computing the volume associated with a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e63583-e511-4e21-9b94-6fa4c8374ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def save_r_arrays_np(folder_path,\n",
    "                    filename,\n",
    "                    circle_r_array, \n",
    "                    random_r_array, \n",
    "                    exact_circle_r_array, \n",
    "                    exact_random_r_array):\n",
    "    \"\"\"\n",
    "    Save r_arrays as a compressed NumPy .npz file.\n",
    "    \"\"\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    np.savez_compressed(\n",
    "        os.path.join(folder_path, filename),\n",
    "        circle_r_array=np.array(circle_r_array, dtype=object),\n",
    "        random_r_array=np.array(random_r_array, dtype=object),\n",
    "        exact_circle_r_array=np.array(exact_circle_r_array, dtype=object),\n",
    "        exact_random_r_array=np.array(exact_random_r_array, dtype=object)\n",
    "    )\n",
    "    \n",
    "    print(f\"Data saved to: {os.path.join(folder_path, filename)}\")\n",
    "\n",
    "def load_r_arrays_np(filepath):\n",
    "    \"\"\"\n",
    "    Load saved r_arrays and return them exactly as stored (in lists).\n",
    "    Returns: (circle_r, random_r, exact_circle_r, exact_random_r) as lists\n",
    "    \"\"\"\n",
    "    data = np.load(filepath, allow_pickle=True)\n",
    "    \n",
    "    # Convert each array back to list (preserving original structure)\n",
    "    def to_list(arr):\n",
    "        if arr.ndim == 0:  # scalar case\n",
    "            return arr.item()\n",
    "        return [to_list(x) if isinstance(x, np.ndarray) else x for x in arr]\n",
    "    \n",
    "    return (\n",
    "        to_list(data['circle_r_array']),\n",
    "        to_list(data['random_r_array']),\n",
    "        to_list(data['exact_circle_r_array']),\n",
    "        to_list(data['exact_random_r_array'])\n",
    "    )\n",
    "    \n",
    "def compute_sampled_volume(r_values, K, dimension):\n",
    "    # Select K random elements (without replacement)\n",
    "    sampled_r = random.sample(r_values, K)\n",
    "    rn_values = [r ** dimension for r in sampled_r]\n",
    "    volume = sum(rn_values) / len(rn_values)\n",
    "    return volume\n",
    "\n",
    "def compute_all_volumes(circle_r_array, random_r_array, \n",
    "                       exact_circle_r_array, exact_random_r_array, \n",
    "                       k, dimension=2):\n",
    "    \"\"\"\n",
    "    Compute volumes for all models using sampled r-values.\n",
    "    \n",
    "    Args:\n",
    "        arrays: lists of r values\n",
    "        k: Number of samples to use for volume computation\n",
    "        dimension: Dimension for volume calculation (default=2)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of four volume lists: (vol_circle, vol_random, vol_circle_exact, vol_random_exact)\n",
    "    \"\"\"\n",
    "    vol_circle, vol_random = [], []\n",
    "    vol_circle_exact, vol_random_exact = [], []\n",
    "    \n",
    "    for model_idx in range(len(circle_r_array)):\n",
    "        # Use min(k, len(array)) to handle cases where k > available samples\n",
    "        n_samples = min(k, len(circle_r_array[model_idx]))\n",
    "        \n",
    "        vol_circle.append(compute_sampled_volume(circle_r_array[model_idx], n_samples, dimension))\n",
    "        vol_random.append(compute_sampled_volume(random_r_array[model_idx], n_samples, dimension))\n",
    "        vol_circle_exact.append(compute_sampled_volume(exact_circle_r_array[model_idx], n_samples, dimension))\n",
    "        vol_random_exact.append(compute_sampled_volume(exact_random_r_array[model_idx], n_samples, dimension))\n",
    "    \n",
    "    return vol_circle, vol_random, vol_circle_exact, vol_random_exact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7621481-a444-49ec-85b0-68b6452e76cb",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "Here, you can run the experiment. Change experimental parameters at will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52eb53a8-0a0b-4af9-8447-aa059e702683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our loss landscape\n",
    "minima_sharp_loc=-1.0\n",
    "minima_wide_loc=1.0\n",
    "sharp_width=0.1\n",
    "wide_width=0.4\n",
    "loss_fn = LossLandscape(minima_sharp_loc=minima_sharp_loc, \n",
    "                 minima_wide_loc=minima_wide_loc,\n",
    "                 sharp_width=sharp_width,\n",
    "                 wide_width=wide_width)\n",
    "\n",
    "# The loss is 1 - gaussian_sharp, which is 0.3935\n",
    "loss_threshold = 0.3935\n",
    "\n",
    "# A family of models, located at the wide minima, with a variety of scale factors\n",
    "scale_factors = [1.0, 2.0, 3.0, 4.0]\n",
    "model_family = [NParameterModel([minima_wide_loc*scale, minima_wide_loc/scale]) for scale in scale_factors]\n",
    "\n",
    "# Maximum number of perturbation directions\n",
    "num_perturb_directions = 1000\n",
    "circle_perturb_vectors = generate_circular_perturbations(num_perturb_directions)\n",
    "random_perturb_vectors = generate_random_perturbations(model_family[0], n = num_perturb_directions)\n",
    "\n",
    "# Coefficients to sample\n",
    "N = 801\n",
    "coefficients = np.linspace(0, 8, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130f499a-7faa-4645-b7f6-af4e20412d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing model 1/4\n",
      "Done circle!\n"
     ]
    }
   ],
   "source": [
    "# Initialize storage for r values\n",
    "# We store the r value for each random direction, and do this for each of the models (defined by different scales)\n",
    "circle_r_array = [[None] for _ in range(len(model_family))]\n",
    "random_r_array = [[None] for _ in range(len(model_family))]\n",
    "\n",
    "exact_circle_r_array = [[None] for _ in range(len(model_family))]\n",
    "exact_random_r_array = [[None] for _ in range(len(model_family))]\n",
    "\n",
    "# The minima and the width\n",
    "a = minima_wide_loc\n",
    "w = wide_width\n",
    "\n",
    "# Go through each member of the model family\n",
    "for model_idx, model in enumerate(model_family):\n",
    "    print(f\"\\nProcessing model {model_idx + 1}/{len(model_family)}\")\n",
    "\n",
    "    ################ CIRCLE ################\n",
    "    ## Numeric circle r\n",
    "    circle_loss_results = wiggle_multiple_directions(\n",
    "        model=model_family[model_idx],\n",
    "        loss_fn=loss_fn,\n",
    "        perturbation_directions=circle_perturb_vectors,\n",
    "        coefficients=coefficients,\n",
    "        #verbose = True,\n",
    "    )\n",
    "\n",
    "    circle_r_values, valid_directions = loss_threshold_crossing(circle_loss_results, loss_threshold)\n",
    "    # Check for invalid directions\n",
    "    if not all(valid_directions):\n",
    "        invalid_count = len([v for v in valid_directions if not v])\n",
    "        print(f\"Circle Warning: {invalid_count}/{len(valid_directions)} directions failed threshold\")\n",
    "    \n",
    "    # Store r_values\n",
    "    circle_r_array[model_idx]= circle_r_values\n",
    "    print (\"Done circle!\")\n",
    "\n",
    "    ################ RANDOM ################\n",
    "    ## Numeric random r\n",
    "    random_loss_results = wiggle_multiple_directions(\n",
    "        model=model_family[model_idx],\n",
    "        loss_fn=loss_fn,\n",
    "        perturbation_directions=random_perturb_vectors,\n",
    "        coefficients=coefficients,\n",
    "        #verbose = True,\n",
    "    )\n",
    "\n",
    "    random_r_values, valid_directions = loss_threshold_crossing(random_loss_results, loss_threshold)\n",
    "    # Check for invalid directions\n",
    "    if not all(valid_directions):\n",
    "        invalid_count = len([v for v in valid_directions if not v])\n",
    "        print(f\"Random Warning: {invalid_count}/{len(valid_directions)} directions failed threshold\")\n",
    "    \n",
    "    # Store r_values\n",
    "    random_r_array[model_idx]= random_r_values\n",
    "    print (\"Done random!\")\n",
    "\n",
    "    ############### EXACT ##############\n",
    "    ## Exact circle r\n",
    "    origin = model_family[model_idx].get_parameter_values()\n",
    "    exact_circle_r_array[model_idx] = compute_r_list(origin, a, w, circle_perturb_vectors)\n",
    "    exact_random_r_array[model_idx] = compute_r_list(origin, a, w, random_perturb_vectors)\n",
    "print (\"Finished computing radii for all models!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9765b1-d3c1-4a2e-b3b3-e030d80ad921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "save_r_arrays_np(\n",
    "    folder_path=f\"experiments/a_{a}_w_{w}_n_perturb_{num_perturb_directions}\",\n",
    "    filename=\"saved_results.npz\",\n",
    "    circle_r_array=circle_r_array,\n",
    "    random_r_array=random_r_array,\n",
    "    exact_circle_r_array=exact_circle_r_array,\n",
    "    exact_random_r_array=exact_random_r_array\n",
    ")\n",
    "\n",
    "# Load data\n",
    "circle_r_array, random_r_array, exact_circle_r_array, exact_random_r_array = load_r_arrays_np(f\"./experiments/a_{a}_w_{w}_n_perturb_{num_perturb_directions}/saved_results.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673d9ac-d253-4013-8443-a4db38c5b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all volumes using all available samples (k = len(volume))\n",
    "vol_circle, vol_random, vol_circle_exact, vol_random_exact = compute_all_volumes(\n",
    "    circle_r_array, \n",
    "    random_r_array,\n",
    "    exact_circle_r_array,\n",
    "    exact_random_r_array,\n",
    "    k=len(circle_r_array[0]),  # Using full sample size\n",
    "    dimension=2\n",
    ")\n",
    "\n",
    "theoretical_volume = analytic_volume(a, w)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot numeric results\n",
    "plt.plot(scale_factors, vol_circle, 'o-', label='Numeric Circle', color='blue')\n",
    "plt.plot(scale_factors, vol_random, 'o-', label='Numeric Random', color='green')\n",
    "\n",
    "# Plot exact results\n",
    "plt.plot(scale_factors, vol_circle_exact, 's--', label='Exact Circle', color='lightblue')\n",
    "plt.plot(scale_factors, vol_random_exact, 's--', label='Exact Random', color='lightgreen')\n",
    "\n",
    "plt.plot(scale_factors, np.ones(len(scale_factors))*theoretical_volume/np.pi, 's--', label='Theory', color='red')\n",
    "\n",
    "# Add plot decorations\n",
    "plt.xlabel('Scale Factor', fontsize=12)\n",
    "plt.ylabel('Volume', fontsize=12)\n",
    "plt.title('Volume vs Scale Factor', fontsize=14)\n",
    "plt.legend(fontsize=20)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 1.2*theoretical_volume/np.pi)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"experiments/a_{a}_w_{w}_n_perturb_{num_perturb_directions}/Volume_Scale.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e46f5-1e3f-4bc9-81f7-e611e1255efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diffusion-env)",
   "language": "python",
   "name": "diffusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
