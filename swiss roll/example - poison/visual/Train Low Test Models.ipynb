{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4494701a-38ed-4662-8e6b-66b8e14fcadf",
   "metadata": {
    "papermill": {
     "duration": 0.002991,
     "end_time": "2025-09-05T11:37:07.801196",
     "exception": false,
     "start_time": "2025-09-05T11:37:07.798205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Low Test Models\n",
    "\n",
    "This notebook is a streamlined notebook for generating minima of low test accuracy through three different means:\n",
    "- Dataset Poisoning\n",
    "- Adding Noise to Data\n",
    "- Decreasing Dataset Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243f018-2c18-476a-82a6-10cdbce9e963",
   "metadata": {
    "papermill": {
     "duration": 0.00324,
     "end_time": "2025-09-05T11:37:07.838832",
     "exception": false,
     "start_time": "2025-09-05T11:37:07.835592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b91824-82ff-4a5a-9a9c-434fa49310c0",
   "metadata": {
    "papermill": {
     "duration": 1.790346,
     "end_time": "2025-09-05T11:37:09.632446",
     "exception": false,
     "start_time": "2025-09-05T11:37:07.842100",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Third-party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Local package imports\n",
    "from minima_volume.dataset_funcs import (\n",
    "    prepare_datasets,\n",
    "    save_dataset,\n",
    "    save_model,\n",
    ")\n",
    "from minima_volume.train_funcs import evaluate, train\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d7d91-a84f-4acd-9ea4-ce6c8b45ed39",
   "metadata": {
    "papermill": {
     "duration": 0.002839,
     "end_time": "2025-09-05T11:37:09.637195",
     "exception": false,
     "start_time": "2025-09-05T11:37:09.634356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb0358d-193d-4228-8a73-baad9a52d6e0",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.0067,
     "end_time": "2025-09-05T11:37:09.644967",
     "exception": false,
     "start_time": "2025-09-05T11:37:09.638267",
     "status": "completed"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# Base Input Parameters\n",
    "# ==============================\n",
    "# --- SEEDS ---\n",
    "data_seed = 0            \n",
    "model_seed = 0           \n",
    "\n",
    "# --- Training configuration ---\n",
    "epochs = 2000            \n",
    "\n",
    "# --- Dataset configuration ---\n",
    "base_data_size = 400      \n",
    "dataset_type = \"poison\"    \n",
    "dataset_quantities = [0, 10, 20, 50, 100]\n",
    "\n",
    "# --- Output configuration ---\n",
    "base_output_dir = \"\"     \n",
    "save_generated_dataset = True   \n",
    "save_generated_models = True    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a4654f-82f0-4c10-be90-e3c6261372a3",
   "metadata": {
    "papermill": {
     "duration": 0.003501,
     "end_time": "2025-09-05T11:37:09.650743",
     "exception": false,
     "start_time": "2025-09-05T11:37:09.647242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model + Dataset Specific Code\n",
    "\n",
    "This is for specific code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a623f55-bdd5-4268-be80-280a8a1e36d6",
   "metadata": {
    "papermill": {
     "duration": 0.097746,
     "end_time": "2025-09-05T11:37:09.749708",
     "exception": false,
     "start_time": "2025-09-05T11:37:09.651962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User specifies the model module name\n",
    "from minima_volume.models import swiss_model_data as model_module\n",
    "\n",
    "test_dataset_size = 2000\n",
    "\n",
    "# Generate dataset\n",
    "x_base, y_base, x_test, y_test = model_module.get_dataset(\n",
    "    base_data_size=base_data_size,\n",
    "    dataset_quantities=dataset_quantities,\n",
    "    test_dataset_size=test_dataset_size,\n",
    "    noise=0.3, # default swiss params\n",
    "    extra_pts=1000,\n",
    "    dataset_type=dataset_type,\n",
    "    seed=data_seed\n",
    ")\n",
    "\n",
    "# Swiss specific initialization parameters\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "hidden_dims = [32]*5\n",
    "\n",
    "# Grab model\n",
    "model_template = model_module.get_model(input_dim=input_dim, hidden_dims=hidden_dims, output_dim=output_dim, device=device, seed=model_seed)\n",
    "\n",
    "# Grab loss and metrics\n",
    "loss_fn = model_module.get_loss_fn()\n",
    "other_metrics = model_module.get_additional_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b444f632-4ed7-4f3d-9f18-19a6cedabed8",
   "metadata": {
    "papermill": {
     "duration": 0.001028,
     "end_time": "2025-09-05T11:37:09.752768",
     "exception": false,
     "start_time": "2025-09-05T11:37:09.751740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training\n",
    "\n",
    "We generate the various datasets used to train our models here, before training them. We record the losses, and what each model was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47509299-2618-4472-b448-a8023647dede",
   "metadata": {
    "papermill": {
     "duration": 436.670622,
     "end_time": "2025-09-05T11:44:26.425934",
     "exception": false,
     "start_time": "2025-09-05T11:37:09.755312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000: Train Loss 0.6884 | Test Loss 0.6928 | accs Train 0.5725 Test 0.5000\n",
      "Epoch 100/2000: Train Loss 0.5159 | Test Loss 0.5772 | accs Train 0.7000 Test 0.6418\n",
      "Epoch 200/2000: Train Loss 0.0234 | Test Loss 0.1278 | accs Train 0.9925 Test 0.9745\n",
      "Epoch 300/2000: Train Loss 0.0060 | Test Loss 0.1337 | accs Train 1.0000 Test 0.9795\n",
      "Epoch 400/2000: Train Loss 0.0008 | Test Loss 0.1370 | accs Train 1.0000 Test 0.9810\n",
      "Epoch 500/2000: Train Loss 0.0003 | Test Loss 0.1422 | accs Train 1.0000 Test 0.9818\n",
      "Epoch 600/2000: Train Loss 0.0002 | Test Loss 0.1451 | accs Train 1.0000 Test 0.9818\n",
      "Epoch 700/2000: Train Loss 0.0001 | Test Loss 0.1451 | accs Train 1.0000 Test 0.9820\n",
      "Epoch 800/2000: Train Loss 0.0001 | Test Loss 0.1445 | accs Train 1.0000 Test 0.9820\n",
      "Epoch 900/2000: Train Loss 0.0001 | Test Loss 0.1440 | accs Train 1.0000 Test 0.9822\n",
      "Epoch 1000/2000: Train Loss 0.0001 | Test Loss 0.1438 | accs Train 1.0000 Test 0.9822\n",
      "Epoch 1100/2000: Train Loss 0.0000 | Test Loss 0.1428 | accs Train 1.0000 Test 0.9825\n",
      "Epoch 1200/2000: Train Loss 0.0000 | Test Loss 0.1416 | accs Train 1.0000 Test 0.9825\n",
      "Epoch 1300/2000: Train Loss 0.0000 | Test Loss 0.1404 | accs Train 1.0000 Test 0.9825\n",
      "Epoch 1400/2000: Train Loss 0.0000 | Test Loss 0.1392 | accs Train 1.0000 Test 0.9825\n",
      "Epoch 1500/2000: Train Loss 0.0000 | Test Loss 0.1381 | accs Train 1.0000 Test 0.9825\n",
      "Epoch 1600/2000: Train Loss 0.0000 | Test Loss 0.1377 | accs Train 1.0000 Test 0.9825\n",
      "Epoch 1700/2000: Train Loss 0.0000 | Test Loss 0.1359 | accs Train 1.0000 Test 0.9830\n",
      "Epoch 1800/2000: Train Loss 0.0000 | Test Loss 0.1344 | accs Train 1.0000 Test 0.9830\n",
      "Epoch 1900/2000: Train Loss 0.0000 | Test Loss 0.1330 | accs Train 1.0000 Test 0.9830\n",
      "Epoch 2000/2000: Train Loss 0.0000 | Test Loss 0.1318 | accs Train 1.0000 Test 0.9832\n",
      "Completed training with 0 additional samples of poison\n",
      "Epoch 1/2000: Train Loss 0.6883 | Test Loss 0.6928 | accs Train 0.5732 Test 0.5000\n",
      "Epoch 100/2000: Train Loss 0.5258 | Test Loss 0.5840 | accs Train 0.6927 Test 0.6452\n",
      "Epoch 200/2000: Train Loss 0.0676 | Test Loss 0.1294 | accs Train 0.9707 Test 0.9683\n",
      "Epoch 300/2000: Train Loss 0.0463 | Test Loss 0.1310 | accs Train 0.9780 Test 0.9653\n",
      "Epoch 400/2000: Train Loss 0.0337 | Test Loss 0.1361 | accs Train 0.9878 Test 0.9653\n",
      "Epoch 500/2000: Train Loss 0.0263 | Test Loss 0.1518 | accs Train 0.9927 Test 0.9633\n",
      "Epoch 600/2000: Train Loss 0.0213 | Test Loss 0.1703 | accs Train 0.9951 Test 0.9623\n",
      "Epoch 700/2000: Train Loss 0.0187 | Test Loss 0.1925 | accs Train 0.9976 Test 0.9600\n",
      "Epoch 800/2000: Train Loss 0.0152 | Test Loss 0.2052 | accs Train 0.9927 Test 0.9600\n",
      "Epoch 900/2000: Train Loss 0.0131 | Test Loss 0.2141 | accs Train 0.9951 Test 0.9603\n",
      "Epoch 1000/2000: Train Loss 0.0117 | Test Loss 0.2312 | accs Train 0.9951 Test 0.9587\n",
      "Epoch 1100/2000: Train Loss 0.0122 | Test Loss 0.2081 | accs Train 0.9951 Test 0.9573\n",
      "Epoch 1200/2000: Train Loss 0.0103 | Test Loss 0.2171 | accs Train 0.9976 Test 0.9603\n",
      "Epoch 1300/2000: Train Loss 0.0095 | Test Loss 0.2254 | accs Train 0.9976 Test 0.9605\n",
      "Epoch 1400/2000: Train Loss 0.0090 | Test Loss 0.2313 | accs Train 0.9976 Test 0.9603\n",
      "Epoch 1500/2000: Train Loss 0.0085 | Test Loss 0.2392 | accs Train 0.9951 Test 0.9597\n",
      "Epoch 1600/2000: Train Loss 0.0120 | Test Loss 0.2692 | accs Train 0.9951 Test 0.9565\n",
      "Epoch 1700/2000: Train Loss 0.0077 | Test Loss 0.2487 | accs Train 0.9976 Test 0.9595\n",
      "Epoch 1800/2000: Train Loss 0.0074 | Test Loss 0.2581 | accs Train 0.9951 Test 0.9593\n",
      "Epoch 1900/2000: Train Loss 0.0072 | Test Loss 0.2650 | accs Train 0.9951 Test 0.9585\n",
      "Epoch 2000/2000: Train Loss 0.0070 | Test Loss 0.2736 | accs Train 0.9951 Test 0.9585\n",
      "Completed training with 10 additional samples of poison\n",
      "Epoch 1/2000: Train Loss 0.6882 | Test Loss 0.6928 | accs Train 0.5738 Test 0.5000\n",
      "Epoch 100/2000: Train Loss 0.5477 | Test Loss 0.5879 | accs Train 0.6762 Test 0.6338\n",
      "Epoch 200/2000: Train Loss 0.1213 | Test Loss 0.1331 | accs Train 0.9524 Test 0.9633\n",
      "Epoch 300/2000: Train Loss 0.0889 | Test Loss 0.1541 | accs Train 0.9595 Test 0.9583\n",
      "Epoch 400/2000: Train Loss 0.0714 | Test Loss 0.1809 | accs Train 0.9667 Test 0.9485\n",
      "Epoch 500/2000: Train Loss 0.0560 | Test Loss 0.2028 | accs Train 0.9786 Test 0.9505\n",
      "Epoch 600/2000: Train Loss 0.0493 | Test Loss 0.2404 | accs Train 0.9786 Test 0.9430\n",
      "Epoch 700/2000: Train Loss 0.0455 | Test Loss 0.2570 | accs Train 0.9810 Test 0.9475\n",
      "Epoch 800/2000: Train Loss 0.0383 | Test Loss 0.2899 | accs Train 0.9833 Test 0.9395\n",
      "Epoch 900/2000: Train Loss 0.0368 | Test Loss 0.3002 | accs Train 0.9833 Test 0.9395\n",
      "Epoch 1000/2000: Train Loss 0.0351 | Test Loss 0.3012 | accs Train 0.9857 Test 0.9430\n",
      "Epoch 1100/2000: Train Loss 0.0333 | Test Loss 0.3043 | accs Train 0.9857 Test 0.9427\n",
      "Epoch 1200/2000: Train Loss 0.0296 | Test Loss 0.3147 | accs Train 0.9857 Test 0.9365\n",
      "Epoch 1300/2000: Train Loss 0.0274 | Test Loss 0.3036 | accs Train 0.9857 Test 0.9385\n",
      "Epoch 1400/2000: Train Loss 0.0264 | Test Loss 0.3177 | accs Train 0.9833 Test 0.9387\n",
      "Epoch 1500/2000: Train Loss 0.0250 | Test Loss 0.3361 | accs Train 0.9881 Test 0.9380\n",
      "Epoch 1600/2000: Train Loss 0.0258 | Test Loss 0.3536 | accs Train 0.9881 Test 0.9360\n",
      "Epoch 1700/2000: Train Loss 0.0219 | Test Loss 0.3674 | accs Train 0.9929 Test 0.9373\n",
      "Epoch 1800/2000: Train Loss 0.0230 | Test Loss 0.3903 | accs Train 0.9881 Test 0.9325\n",
      "Epoch 1900/2000: Train Loss 0.0174 | Test Loss 0.3991 | accs Train 0.9905 Test 0.9343\n",
      "Epoch 2000/2000: Train Loss 0.0170 | Test Loss 0.4152 | accs Train 0.9929 Test 0.9333\n",
      "Completed training with 20 additional samples of poison\n",
      "Epoch 1/2000: Train Loss 0.6899 | Test Loss 0.6928 | accs Train 0.5533 Test 0.5000\n",
      "Epoch 100/2000: Train Loss 0.5708 | Test Loss 0.5888 | accs Train 0.6644 Test 0.6260\n",
      "Epoch 200/2000: Train Loss 0.2884 | Test Loss 0.2204 | accs Train 0.8844 Test 0.9450\n",
      "Epoch 300/2000: Train Loss 0.2557 | Test Loss 0.2237 | accs Train 0.8844 Test 0.9503\n",
      "Epoch 400/2000: Train Loss 0.2351 | Test Loss 0.2507 | accs Train 0.8933 Test 0.9413\n",
      "Epoch 500/2000: Train Loss 0.2154 | Test Loss 0.2871 | accs Train 0.9044 Test 0.9370\n",
      "Epoch 600/2000: Train Loss 0.2033 | Test Loss 0.3325 | accs Train 0.9089 Test 0.9357\n",
      "Epoch 700/2000: Train Loss 0.1898 | Test Loss 0.3763 | accs Train 0.9133 Test 0.9270\n",
      "Epoch 800/2000: Train Loss 0.1800 | Test Loss 0.4234 | accs Train 0.9222 Test 0.9180\n",
      "Epoch 900/2000: Train Loss 0.1669 | Test Loss 0.4621 | accs Train 0.9267 Test 0.9055\n",
      "Epoch 1000/2000: Train Loss 0.1610 | Test Loss 0.4915 | accs Train 0.9289 Test 0.9000\n",
      "Epoch 1100/2000: Train Loss 0.1566 | Test Loss 0.5603 | accs Train 0.9289 Test 0.8838\n",
      "Epoch 1200/2000: Train Loss 0.1515 | Test Loss 0.5553 | accs Train 0.9289 Test 0.8938\n",
      "Epoch 1300/2000: Train Loss 0.1403 | Test Loss 0.5962 | accs Train 0.9311 Test 0.8870\n",
      "Epoch 1400/2000: Train Loss 0.1342 | Test Loss 0.6242 | accs Train 0.9244 Test 0.8822\n",
      "Epoch 1500/2000: Train Loss 0.1292 | Test Loss 0.6466 | accs Train 0.9400 Test 0.8845\n",
      "Epoch 1600/2000: Train Loss 0.1294 | Test Loss 0.6853 | accs Train 0.9400 Test 0.8760\n",
      "Epoch 1700/2000: Train Loss 0.1226 | Test Loss 0.7163 | accs Train 0.9422 Test 0.8725\n",
      "Epoch 1800/2000: Train Loss 0.1192 | Test Loss 0.7116 | accs Train 0.9378 Test 0.8758\n",
      "Epoch 1900/2000: Train Loss 0.1453 | Test Loss 0.7988 | accs Train 0.9289 Test 0.8655\n",
      "Epoch 2000/2000: Train Loss 0.1170 | Test Loss 0.8035 | accs Train 0.9444 Test 0.8740\n",
      "Completed training with 50 additional samples of poison\n",
      "Epoch 1/2000: Train Loss 0.6903 | Test Loss 0.6929 | accs Train 0.5480 Test 0.5000\n",
      "Epoch 100/2000: Train Loss 0.5900 | Test Loss 0.5851 | accs Train 0.7100 Test 0.7252\n",
      "Epoch 200/2000: Train Loss 0.4190 | Test Loss 0.3286 | accs Train 0.8100 Test 0.9157\n",
      "Epoch 300/2000: Train Loss 0.3847 | Test Loss 0.3210 | accs Train 0.8220 Test 0.9133\n",
      "Epoch 400/2000: Train Loss 0.3656 | Test Loss 0.3425 | accs Train 0.8300 Test 0.8960\n",
      "Epoch 500/2000: Train Loss 0.3513 | Test Loss 0.3567 | accs Train 0.8320 Test 0.8855\n",
      "Epoch 600/2000: Train Loss 0.3363 | Test Loss 0.3592 | accs Train 0.8360 Test 0.8798\n",
      "Epoch 700/2000: Train Loss 0.3271 | Test Loss 0.3890 | accs Train 0.8420 Test 0.8702\n",
      "Epoch 800/2000: Train Loss 0.3129 | Test Loss 0.3969 | accs Train 0.8440 Test 0.8602\n",
      "Epoch 900/2000: Train Loss 0.3026 | Test Loss 0.4116 | accs Train 0.8460 Test 0.8512\n",
      "Epoch 1000/2000: Train Loss 0.2920 | Test Loss 0.4448 | accs Train 0.8520 Test 0.8383\n",
      "Epoch 1100/2000: Train Loss 0.2825 | Test Loss 0.4420 | accs Train 0.8580 Test 0.8458\n",
      "Epoch 1200/2000: Train Loss 0.2825 | Test Loss 0.4492 | accs Train 0.8700 Test 0.8403\n",
      "Epoch 1300/2000: Train Loss 0.2693 | Test Loss 0.4983 | accs Train 0.8700 Test 0.8253\n",
      "Epoch 1400/2000: Train Loss 0.2625 | Test Loss 0.4958 | accs Train 0.8760 Test 0.8345\n",
      "Epoch 1500/2000: Train Loss 0.2623 | Test Loss 0.5124 | accs Train 0.8740 Test 0.8400\n",
      "Epoch 1600/2000: Train Loss 0.2519 | Test Loss 0.5149 | accs Train 0.8840 Test 0.8317\n",
      "Epoch 1700/2000: Train Loss 0.2512 | Test Loss 0.5475 | accs Train 0.8820 Test 0.8245\n",
      "Epoch 1800/2000: Train Loss 0.2472 | Test Loss 0.5638 | accs Train 0.8780 Test 0.8240\n",
      "Epoch 1900/2000: Train Loss 0.2403 | Test Loss 0.5419 | accs Train 0.8840 Test 0.8345\n",
      "Epoch 2000/2000: Train Loss 0.2506 | Test Loss 0.5872 | accs Train 0.8760 Test 0.8270\n",
      "Completed training with 100 additional samples of poison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000: Train Loss 0.1904 | Test Loss 1.2123 | accs Train 0.9000 Test 0.6130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/1000: Train Loss 0.0048 | Test Loss 3.6333 | accs Train 1.0000 Test 0.6172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000: Train Loss 0.0005 | Test Loss 4.2644 | accs Train 1.0000 Test 0.6195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000: Train Loss 0.0002 | Test Loss 4.5421 | accs Train 1.0000 Test 0.6190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000: Train Loss 0.0001 | Test Loss 4.7210 | accs Train 1.0000 Test 0.6188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000: Train Loss 0.0001 | Test Loss 4.8526 | accs Train 1.0000 Test 0.6180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700/1000: Train Loss 0.0001 | Test Loss 4.9550 | accs Train 1.0000 Test 0.6185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800/1000: Train Loss 0.0000 | Test Loss 5.0394 | accs Train 1.0000 Test 0.6190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/1000: Train Loss 0.0000 | Test Loss 5.1101 | accs Train 1.0000 Test 0.6185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000: Train Loss 0.0000 | Test Loss 5.1699 | accs Train 1.0000 Test 0.6192\n",
      "Completed training with 0 additional samples of data\n",
      "Epoch 1/1000: Train Loss 0.6898 | Test Loss 0.6926 | accs Train 0.5600 Test 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000: Train Loss 0.3318 | Test Loss 0.9050 | accs Train 0.8400 Test 0.6255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/1000: Train Loss 0.1063 | Test Loss 2.5634 | accs Train 0.9400 Test 0.5935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000: Train Loss 0.0575 | Test Loss 3.4665 | accs Train 0.9800 Test 0.6360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000: Train Loss 0.0186 | Test Loss 4.4117 | accs Train 1.0000 Test 0.6565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000: Train Loss 0.0024 | Test Loss 5.4001 | accs Train 1.0000 Test 0.6765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000: Train Loss 0.0009 | Test Loss 5.7611 | accs Train 1.0000 Test 0.6870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700/1000: Train Loss 0.0005 | Test Loss 5.9667 | accs Train 1.0000 Test 0.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800/1000: Train Loss 0.0003 | Test Loss 6.1055 | accs Train 1.0000 Test 0.6970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/1000: Train Loss 0.0002 | Test Loss 6.2100 | accs Train 1.0000 Test 0.6997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000: Train Loss 0.0002 | Test Loss 6.2990 | accs Train 1.0000 Test 0.7025\n",
      "Completed training with 30 additional samples of data\n",
      "Epoch 1/1000: Train Loss 0.6974 | Test Loss 0.6923 | accs Train 0.4750 Test 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000: Train Loss 0.4798 | Test Loss 0.6707 | accs Train 0.7083 Test 0.6270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/1000: Train Loss 0.2029 | Test Loss 0.7486 | accs Train 0.9083 Test 0.7582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000: Train Loss 0.0646 | Test Loss 0.7200 | accs Train 1.0000 Test 0.8720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000: Train Loss 0.0019 | Test Loss 0.7250 | accs Train 1.0000 Test 0.9133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000: Train Loss 0.0005 | Test Loss 0.7637 | accs Train 1.0000 Test 0.9163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000: Train Loss 0.0003 | Test Loss 0.7964 | accs Train 1.0000 Test 0.9177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700/1000: Train Loss 0.0002 | Test Loss 0.8239 | accs Train 1.0000 Test 0.9183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800/1000: Train Loss 0.0001 | Test Loss 0.8418 | accs Train 1.0000 Test 0.9193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/1000: Train Loss 0.0001 | Test Loss 0.8546 | accs Train 1.0000 Test 0.9197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000: Train Loss 0.0001 | Test Loss 0.8645 | accs Train 1.0000 Test 0.9203\n",
      "Completed training with 100 additional samples of data\n",
      "Epoch 1/1000: Train Loss 0.6934 | Test Loss 0.6922 | accs Train 0.5125 Test 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000: Train Loss 0.5296 | Test Loss 0.5817 | accs Train 0.6750 Test 0.6488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/1000: Train Loss 0.0200 | Test Loss 0.0319 | accs Train 0.9969 Test 0.9912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000: Train Loss 0.0020 | Test Loss 0.0108 | accs Train 1.0000 Test 0.9965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000: Train Loss 0.0006 | Test Loss 0.0092 | accs Train 1.0000 Test 0.9970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000: Train Loss 0.0003 | Test Loss 0.0091 | accs Train 1.0000 Test 0.9970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000: Train Loss 0.0002 | Test Loss 0.0092 | accs Train 1.0000 Test 0.9972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700/1000: Train Loss 0.0001 | Test Loss 0.0094 | accs Train 1.0000 Test 0.9972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800/1000: Train Loss 0.0001 | Test Loss 0.0096 | accs Train 1.0000 Test 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/1000: Train Loss 0.0001 | Test Loss 0.0098 | accs Train 1.0000 Test 0.9972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000: Train Loss 0.0000 | Test Loss 0.0100 | accs Train 1.0000 Test 0.9975\n",
      "Completed training with 300 additional samples of data\n",
      "Epoch 1/1000: Train Loss 0.6934 | Test Loss 0.6922 | accs Train 0.5125 Test 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000: Train Loss 0.5600 | Test Loss 0.5936 | accs Train 0.6861 Test 0.6567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/1000: Train Loss 0.0357 | Test Loss 0.0370 | accs Train 0.9903 Test 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000: Train Loss 0.0023 | Test Loss 0.0117 | accs Train 1.0000 Test 0.9958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000: Train Loss 0.0006 | Test Loss 0.0118 | accs Train 1.0000 Test 0.9962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000: Train Loss 0.0003 | Test Loss 0.0122 | accs Train 1.0000 Test 0.9968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/1000: Train Loss 0.0002 | Test Loss 0.0127 | accs Train 1.0000 Test 0.9968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700/1000: Train Loss 0.0001 | Test Loss 0.0130 | accs Train 1.0000 Test 0.9968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800/1000: Train Loss 0.0001 | Test Loss 0.0134 | accs Train 1.0000 Test 0.9968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/1000: Train Loss 0.0001 | Test Loss 0.0136 | accs Train 1.0000 Test 0.9968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000: Train Loss 0.0000 | Test Loss 0.0139 | accs Train 1.0000 Test 0.9968\n",
      "Completed training with 700 additional samples of data\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Prepare datasets\n",
    "# ==============================\n",
    "x_base_train, y_base_train, x_additional, y_additional = prepare_datasets(\n",
    "    x_base=x_base,\n",
    "    y_base=y_base,\n",
    "    dataset_type=dataset_type,\n",
    "    dataset_quantities=dataset_quantities,\n",
    "    base_data_size=base_data_size,\n",
    "    data_seed=data_seed,\n",
    "    seed_1=None,\n",
    "    seed_2=None,\n",
    ")\n",
    "\n",
    "x_base_train = x_base_train.to(device)\n",
    "y_base_train = y_base_train.to(device)\n",
    "x_additional = x_additional.to(device)\n",
    "y_additional = y_additional.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "# ==============================\n",
    "# Training loop\n",
    "# ==============================\n",
    "all_models = []\n",
    "\n",
    "for additional_data in dataset_quantities:\n",
    "    # Assemble training dataset\n",
    "    x_train = torch.cat([x_base_train, x_additional[:additional_data]], dim=0)\n",
    "    y_train = torch.cat([y_base_train, y_additional[:additional_data]], dim=0)\n",
    "\n",
    "    # Initialize model (defined in the model-specific file)\n",
    "    torch.manual_seed(model_seed)\n",
    "    model = copy.deepcopy(model_template)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    batch_size = len(x_train)\n",
    "\n",
    "    # Train model\n",
    "    train_loss, train_other_metrics, test_loss, test_other_metrics = train(\n",
    "        model = model,\n",
    "        x_train = x_train, y_train = y_train,\n",
    "        x_test = x_test, y_test = y_test,\n",
    "        loss_fn = loss_fn,\n",
    "        metrics = other_metrics,\n",
    "        optimizer = optimizer,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose_every=100,\n",
    "    )\n",
    "    \n",
    "    # Build dictionary dynamically for additional metrics\n",
    "    train_metrics_dict = {}\n",
    "    test_metrics_dict = {}\n",
    "    if train_other_metrics is not None:\n",
    "        # train_other_metrics is a list of dicts per epoch\n",
    "        for metric_name in train_other_metrics[0].keys():  # keys from first epoch\n",
    "            train_metrics_dict[f\"train_{metric_name}\"] = [m[metric_name] for m in train_other_metrics]\n",
    "            test_metrics_dict[f\"test_{metric_name}\"] = [m[metric_name] for m in test_other_metrics]\n",
    "    \n",
    "    # Store results\n",
    "    trained_model = {\n",
    "        \"model\": model,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"additional_data\": additional_data,\n",
    "        \"dataset_type\": dataset_type,\n",
    "        **train_metrics_dict,  # dynamically include additional metrics\n",
    "        **test_metrics_dict,\n",
    "    }\n",
    "    \n",
    "    all_models.append(trained_model)\n",
    "\n",
    "    print(f\"Completed training with {additional_data} additional samples of {dataset_type}\")\n",
    "\n",
    "    # Free memory (important for large GPU datasets)\n",
    "    del x_train, y_train\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d68857d-0539-4939-ae00-914b25e7a01d",
   "metadata": {
    "papermill": {
     "duration": 0.004065,
     "end_time": "2025-09-05T11:44:26.433556",
     "exception": false,
     "start_time": "2025-09-05T11:44:26.429491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ceddb5a-bf51-48cd-8e8f-0efdb934fab7",
   "metadata": {
    "papermill": {
     "duration": 0.066932,
     "end_time": "2025-09-05T11:44:26.506555",
     "exception": false,
     "start_time": "2025-09-05T11:44:26.439623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== True Generalization ===\n",
      "   0 samples | Test Loss: 0.1318 | accs: 0.9832\n",
      "  10 samples | Test Loss: 0.2736 | accs: 0.9585\n",
      "  20 samples | Test Loss: 0.4152 | accs: 0.9333\n",
      "  50 samples | Test Loss: 0.8035 | accs: 0.8740\n",
      " 100 samples | Test Loss: 0.5872 | accs: 0.8270\n",
      "\n",
      "=== Model Diagnostics by Training Data ===\n",
      "\n",
      "Dataset type: poison, additional samples: 0\n",
      " Model    0 | Train Loss: 0.0000 | accs: 1.0000\n",
      " Model   10 | Train Loss: 0.0031 | accs: 0.9975\n",
      " Model   20 | Train Loss: 0.0100 | accs: 0.9950\n",
      " Model   50 | Train Loss: 0.0593 | accs: 0.9775\n",
      " Model  100 | Train Loss: 0.1451 | accs: 0.9550\n",
      "\n",
      "Dataset type: poison, additional samples: 10\n",
      " Model    0 | Train Loss: 0.2780 | accs: 0.9756\n",
      " Model   10 | Train Loss: 0.0070 | accs: 0.9951\n",
      " Model   20 | Train Loss: 0.0145 | accs: 0.9927\n",
      " Model   50 | Train Loss: 0.0688 | accs: 0.9732\n",
      " Model  100 | Train Loss: 0.1570 | accs: 0.9488\n",
      "\n",
      "Dataset type: poison, additional samples: 20\n",
      " Model    0 | Train Loss: 0.5703 | accs: 0.9524\n",
      " Model   10 | Train Loss: 0.4043 | accs: 0.9714\n",
      " Model   20 | Train Loss: 0.0171 | accs: 0.9905\n",
      " Model   50 | Train Loss: 0.0795 | accs: 0.9643\n",
      " Model  100 | Train Loss: 0.1662 | accs: 0.9405\n",
      "\n",
      "Dataset type: poison, additional samples: 50\n",
      " Model    0 | Train Loss: 1.5050 | accs: 0.8889\n",
      " Model   10 | Train Loss: 1.8659 | accs: 0.9067\n",
      " Model   20 | Train Loss: 1.4058 | accs: 0.9244\n",
      " Model   50 | Train Loss: 0.1169 | accs: 0.9400\n",
      " Model  100 | Train Loss: 0.2058 | accs: 0.9200\n",
      "\n",
      "Dataset type: poison, additional samples: 100\n",
      " Model    0 | Train Loss: 2.8440 | accs: 0.8000\n",
      " Model   10 | Train Loss: 3.8810 | accs: 0.8180\n",
      " Model   20 | Train Loss: 3.6621 | accs: 0.8400\n",
      " Model   50 | Train Loss: 1.2839 | accs: 0.8520\n",
      " Model  100 | Train Loss: 0.2475 | accs: 0.8840\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Summary of Training Results\n",
    "# ====================================\n",
    "print(\"=== True Generalization ===\")\n",
    "for model_data in all_models:\n",
    "    model = model_data[\"model\"]\n",
    "    additional_data = model_data[\"additional_data\"]\n",
    "\n",
    "    test_loss, test_metrics = evaluate(\n",
    "        model=model,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        loss_fn=loss_fn,\n",
    "        metrics=other_metrics\n",
    "    )\n",
    "\n",
    "    metrics_str = \" | \".join([f\"{name}: {val:.4f}\" for name, val in test_metrics.items()])\n",
    "    print(\n",
    "        f\"{additional_data:>4} samples | \"\n",
    "        f\"Test Loss: {test_loss:.4f}\" + (f\" | {metrics_str}\" if metrics_str else \"\")\n",
    "    )\n",
    "\n",
    "print(\"\\n=== Model Diagnostics by Training Data ===\")\n",
    "for additional_data in dataset_quantities:\n",
    "    # Build dataset with this many additional samples\n",
    "    x_train = torch.cat([x_base_train, x_additional[:additional_data]], dim=0)\n",
    "    y_train = torch.cat([y_base_train, y_additional[:additional_data]], dim=0)\n",
    "\n",
    "    print(f\"\\nDataset type: {dataset_type}, additional samples: {additional_data}\")\n",
    "\n",
    "    for model_data in all_models:\n",
    "        model = model_data[\"model\"]\n",
    "        model_additional_data = model_data[\"additional_data\"]\n",
    "\n",
    "        train_loss, train_metrics = evaluate(\n",
    "            model=model,\n",
    "            x_test=x_train,\n",
    "            y_test=y_train,\n",
    "            loss_fn=loss_fn,\n",
    "            metrics=other_metrics\n",
    "        )\n",
    "\n",
    "        metrics_str = \" | \".join([f\"{name}: {val:.4f}\" for name, val in train_metrics.items()])\n",
    "        print(\n",
    "            f\" Model {model_additional_data:>4} | \"\n",
    "            f\"Train Loss: {train_loss:.4f}\" + (f\" | {metrics_str}\" if metrics_str else \"\")\n",
    "        )\n",
    "\n",
    "    # Free memory if large\n",
    "    del x_train, y_train\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d747e684-36dc-4c51-803d-9a42d0f2db29",
   "metadata": {
    "papermill": {
     "duration": 0.005873,
     "end_time": "2025-09-05T11:44:26.516448",
     "exception": false,
     "start_time": "2025-09-05T11:44:26.510575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model + Data Specific Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b2f4a9-2bd1-4d25-b726-3b0023e81698",
   "metadata": {
    "papermill": {
     "duration": 2.693351,
     "end_time": "2025-09-05T11:44:29.212302",
     "exception": false,
     "start_time": "2025-09-05T11:44:26.518951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(model_module)\n",
    "\n",
    "model_module.verify_model_results(\n",
    "    all_models=all_models,\n",
    "    x_base_train=x_base_train,\n",
    "    y_base_train=y_base_train,\n",
    "    x_additional=x_additional,\n",
    "    y_additional=y_additional,\n",
    "    x_test=x_test,\n",
    "    y_test=y_test,\n",
    "    dataset_quantities=dataset_quantities,\n",
    "    dataset_type=dataset_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91dd774-874f-446e-85f0-79dc55796ee4",
   "metadata": {
    "papermill": {
     "duration": 0.006067,
     "end_time": "2025-09-05T11:44:29.225458",
     "exception": false,
     "start_time": "2025-09-05T11:44:29.219391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32553783-d0ce-4eb8-8514-261dc643ca2a",
   "metadata": {
    "papermill": {
     "duration": 0.038907,
     "end_time": "2025-09-05T11:44:29.277085",
     "exception": false,
     "start_time": "2025-09-05T11:44:29.238178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset saved to models_and_data\\dataset.pt\n",
      "Saved dataset to models_and_data/dataset.pt\n",
      "✅ Model saved to models_and_data\\model_additional_0.pt\n",
      "Saved model: models_and_data/model_additional_0.pt\n",
      "✅ Model saved to models_and_data\\model_additional_10.pt\n",
      "Saved model: models_and_data/model_additional_10.pt\n",
      "✅ Model saved to models_and_data\\model_additional_20.pt\n",
      "Saved model: models_and_data/model_additional_20.pt\n",
      "✅ Model saved to models_and_data\\model_additional_50.pt\n",
      "Saved model: models_and_data/model_additional_50.pt\n",
      "✅ Model saved to models_and_data\\model_additional_100.pt\n",
      "Saved model: models_and_data/model_additional_100.pt\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Save Datasets and Models\n",
    "# ====================================\n",
    "output_folder = \"models_and_data\"\n",
    "# Save dataset (Possible to skip)\n",
    "if save_generated_dataset:\n",
    "    save_dataset(\n",
    "        folder=output_folder,\n",
    "        filename=\"dataset.pt\",\n",
    "        x_base_train=x_base_train,\n",
    "        y_base_train=y_base_train,\n",
    "        x_additional=x_additional,\n",
    "        y_additional=y_additional,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        dataset_quantities=dataset_quantities,\n",
    "        dataset_type=dataset_type,\n",
    "    )\n",
    "    print(f\"Saved dataset to {output_folder}/dataset.pt\")\n",
    "\n",
    "# Save trained models\n",
    "if save_generated_models:\n",
    "    for model_data in all_models:\n",
    "        filename = f\"model_additional_{model_data['additional_data']}.pt\"\n",
    "        save_model(\n",
    "            folder=output_folder,\n",
    "            filename=filename,\n",
    "            model=model_data[\"model\"],\n",
    "            train_loss=model_data[\"train_loss\"],\n",
    "            train_accs=model_data[\"train_accs\"],\n",
    "            test_loss=model_data[\"test_loss\"],\n",
    "            test_accs=model_data[\"test_accs\"],\n",
    "            additional_data=model_data[\"additional_data\"],\n",
    "            dataset_type=model_data[\"dataset_type\"],\n",
    "        )\n",
    "        print(f\"Saved model: {output_folder}/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530ae37-14b3-4d87-a88f-b8c868788a2c",
   "metadata": {
    "papermill": {
     "duration": 0.01442,
     "end_time": "2025-09-05T11:44:29.308598",
     "exception": false,
     "start_time": "2025-09-05T11:44:29.294178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diffusion-env)",
   "language": "python",
   "name": "diffusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 443.940673,
   "end_time": "2025-09-05T11:44:30.414734",
   "environment_variables": {},
   "exception": null,
   "input_path": "Train Low Test Models.ipynb",
   "output_path": "Train Low Test Models.ipynb",
   "parameters": {},
   "start_time": "2025-09-05T11:37:06.474061",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
