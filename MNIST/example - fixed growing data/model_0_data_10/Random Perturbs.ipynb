{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4494701a-38ed-4662-8e6b-66b8e14fcadf",
   "metadata": {},
   "source": [
    "# Random Perturbations\n",
    "\n",
    "Streamlined notebook for evaluating random perturbations on saved models and datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243f018-2c18-476a-82a6-10cdbce9e963",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b91824-82ff-4a5a-9a9c-434fa49310c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T15:00:07.582468Z",
     "iopub.status.busy": "2025-10-29T15:00:07.582335Z",
     "iopub.status.idle": "2025-10-29T15:00:08.424606Z",
     "shell.execute_reply": "2025-10-29T15:00:08.423771Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Third-party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Local package imports\n",
    "from minima_volume.perturb_funcs import ( analyze_wiggles_metrics )\n",
    "\n",
    "from minima_volume.dataset_funcs import (\n",
    "    load_dataset,\n",
    "    load_model,\n",
    "    load_models_and_data,\n",
    "    prepare_datasets,\n",
    "    tensor_to_list,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d7d91-a84f-4acd-9ea4-ce6c8b45ed39",
   "metadata": {},
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acb0358d-193d-4228-8a73-baad9a52d6e0",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-10-29T15:00:08.426281Z",
     "iopub.status.busy": "2025-10-29T15:00:08.426117Z",
     "iopub.status.idle": "2025-10-29T15:00:08.428362Z",
     "shell.execute_reply": "2025-10-29T15:00:08.427954Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m coefficients \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Other Configuration\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m dataset_quantities \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m2000\u001b[39m, \u001b[38;5;241m5000\u001b[39m, \u001b[38;5;241m10000\u001b[39m]\n\u001b[1;32m     10\u001b[0m base_output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m coefficients \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Other Configuration\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m dataset_quantities \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m2000\u001b[39m, \u001b[38;5;241m5000\u001b[39m, \u001b[38;5;241m10000\u001b[39m]\n\u001b[1;32m     10\u001b[0m base_output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:634\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1112\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1090\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:494\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/minima-volume-project/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2188\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2185\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2187\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2188\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2190\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2193\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/minima-volume-project/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2257\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2255\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2257\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2258\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2260\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/minima-volume-project/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/minima-volume-project/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Perturbation Configuration\n",
    "perturbation_seed = 1\n",
    "num_directions = 50\n",
    "N = 200\n",
    "x = np.linspace(0, 1, N)\n",
    "coefficients = x**2\n",
    "\n",
    "# Other Configuration\n",
    "dataset_quantities = [0, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "base_output_dir = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6af0fc-d0a3-4793-8ca0-33c9461c6777",
   "metadata": {},
   "source": [
    "## Model + Dataset Specific Code\n",
    "\n",
    "This is for model and dataset specific code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "389d62b5-59f9-43ff-9c59-8e57e3d39f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T15:00:08.429600Z",
     "iopub.status.busy": "2025-10-29T15:00:08.429506Z",
     "iopub.status.idle": "2025-10-29T15:00:08.960864Z",
     "shell.execute_reply": "2025-10-29T15:00:08.960319Z"
    }
   },
   "outputs": [],
   "source": [
    "# User specifies the model module name\n",
    "from minima_volume.models import MNIST_model_data as model_module\n",
    "\n",
    "# Generate dataset\n",
    "#x_base, y_base, x_test, y_test = model_module.get_dataset(\n",
    "#    device = device\n",
    "#)\n",
    "\n",
    "# MNIST specific initialization parameters\n",
    "hidden_dims = [256, 128]\n",
    "\n",
    "# Grab model\n",
    "model_template = model_module.get_model(hidden_dims=hidden_dims, device=device, seed=0)\n",
    "\n",
    "# Grab loss and metrics\n",
    "loss_fn = model_module.get_loss_fn()\n",
    "other_metrics = model_module.get_additional_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b444f632-4ed7-4f3d-9f18-19a6cedabed8",
   "metadata": {},
   "source": [
    "## Loading Model and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47dff34d-5a53-49d0-a3df-d1306cecd722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T15:00:08.962726Z",
     "iopub.status.busy": "2025-10-29T15:00:08.962509Z",
     "iopub.status.idle": "2025-10-29T15:00:09.165785Z",
     "shell.execute_reply": "2025-10-29T15:00:09.164229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for models and dataset in: models_and_data\n",
      "Found 8 model files:\n",
      "  - model_additional_0.pt\n",
      "  - model_additional_100.pt\n",
      "  - model_additional_10000.pt\n",
      "  - model_additional_200.pt\n",
      "  - model_additional_2000.pt\n",
      "  - model_additional_5000.pt\n",
      "  - model_additional_500.pt\n",
      "  - model_additional_1000.pt\n",
      "✅ Model loaded into provided instance from models_and_data/model_additional_0.pt\n",
      "Successfully loaded: model_additional_0.pt\n",
      "✅ Model loaded into provided instance from models_and_data/model_additional_100.pt\n",
      "Successfully loaded: model_additional_100.pt\n",
      "✅ Model loaded into provided instance from models_and_data/model_additional_10000.pt\n",
      "Successfully loaded: model_additional_10000.pt\n",
      "✅ Model loaded into provided instance from models_and_data/model_additional_200.pt\n",
      "Successfully loaded: model_additional_200.pt\n",
      "✅ Model loaded into provided instance from models_and_data/model_additional_2000.pt\n",
      "Successfully loaded: model_additional_2000.pt\n",
      "✅ Model loaded into provided instance from models_and_data/model_additional_5000.pt\n",
      "Successfully loaded: model_additional_5000.pt\n",
      "✅ Model loaded into provided instance from models_and_data/model_additional_500.pt\n",
      "Successfully loaded: model_additional_500.pt\n",
      "✅ Model loaded into provided instance from models_and_data/model_additional_1000.pt\n",
      "Successfully loaded: model_additional_1000.pt\n",
      "\n",
      "Model data loaded from all models:\n",
      "Model 0 (model_additional_0.pt):\n",
      "  - Additional data: 0\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 100 entries\n",
      "  - Test accuracies: 100 entries\n",
      "Model 1 (model_additional_100.pt):\n",
      "  - Additional data: 100\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 100 entries\n",
      "  - Test accuracies: 100 entries\n",
      "Model 2 (model_additional_10000.pt):\n",
      "  - Additional data: 10000\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 100 entries\n",
      "  - Test accuracies: 100 entries\n",
      "Model 3 (model_additional_200.pt):\n",
      "  - Additional data: 200\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 100 entries\n",
      "  - Test accuracies: 100 entries\n",
      "Model 4 (model_additional_2000.pt):\n",
      "  - Additional data: 2000\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 100 entries\n",
      "  - Test accuracies: 100 entries\n",
      "Model 5 (model_additional_5000.pt):\n",
      "  - Additional data: 5000\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 100 entries\n",
      "  - Test accuracies: 100 entries\n",
      "Model 6 (model_additional_500.pt):\n",
      "  - Additional data: 500\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 100 entries\n",
      "  - Test accuracies: 100 entries\n",
      "Model 7 (model_additional_1000.pt):\n",
      "  - Additional data: 1000\n",
      "  - Dataset type: data\n",
      "  - Training accuracies: 100 entries\n",
      "  - Test accuracies: 100 entries\n",
      "\n",
      "Loading dataset...\n",
      "Using dataset file: dataset.pt\n",
      "✅ Dataset loaded from models_and_data/dataset.pt\n",
      "Dataset type: data\n",
      "Dataset quantities: [0, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
      "\n",
      "Tensor shapes:\n",
      "  x_base_train: torch.Size([1000, 1, 28, 28])\n",
      "  y_base_train: torch.Size([1000])\n",
      "  x_additional: torch.Size([10000, 1, 28, 28])\n",
      "  y_additional: torch.Size([10000])\n",
      "  x_test: torch.Size([10000, 1, 28, 28])\n",
      "  y_test: torch.Size([10000])\n",
      "Reconstructed 8 trained models\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Load Trained Models and Dataset\n",
    "# ====================================\n",
    "target_dir = \"models_and_data\"  # relative path\n",
    "loaded_models, loaded_model_data, loaded_dataset = load_models_and_data(\n",
    "    model_template=model_template,\n",
    "    target_dir=target_dir,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Dataset Info\n",
    "dataset_type = loaded_dataset['dataset_type']\n",
    "print(f\"Dataset type: {dataset_type}\")\n",
    "print(f\"Dataset quantities: {loaded_dataset['dataset_quantities']}\")\n",
    "\n",
    "print(\"\\nTensor shapes:\")\n",
    "for key in [\"x_base_train\", \"y_base_train\", \"x_additional\", \"y_additional\", \"x_test\", \"y_test\"]:\n",
    "    shape = getattr(loaded_dataset[key], \"shape\", None)\n",
    "    print(f\"  {key}: {shape if shape is not None else 'None'}\")\n",
    "\n",
    "# Reconstruct trained_model dicts safely.\n",
    "# If the loss or accuracy or additional metrics happen to be\n",
    "# tensors, they get safely converted to lists.\n",
    "all_models = [\n",
    "    {\n",
    "        \"model\": model,\n",
    "        **{\n",
    "            k: tensor_to_list(model_data[k], key_path=k)\n",
    "            for k in [\"train_loss\", \"train_accs\", \"test_loss\", \"test_accs\", \"additional_data\", \"dataset_type\"]\n",
    "        },\n",
    "    }\n",
    "    for model, model_data in zip(loaded_models, loaded_model_data)\n",
    "]\n",
    "print(f\"Reconstructed {len(all_models)} trained models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e6661-c42d-43b7-9ddd-291d56ff910f",
   "metadata": {},
   "source": [
    "## Perturbations\n",
    "\n",
    "Using the saved datasets, we perform model perturbations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e1b83dd-2850-45f2-b9b3-e7ead77b93b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T15:00:09.170960Z",
     "iopub.status.busy": "2025-10-29T15:00:09.170763Z",
     "iopub.status.idle": "2025-10-29T15:00:09.330563Z",
     "shell.execute_reply": "2025-10-29T15:00:09.329760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters of the perturbation is 235146\n",
      "Testing on data with 0 samples - 50 directions\n",
      "Testing model trained on 0 additional data.\n",
      "Loss: 0.5438\n",
      "Accs: 0.8863\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m y_test \u001b[38;5;241m=\u001b[39m loaded_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Loss function and metrics already grabbed from the model module\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43manalyze_wiggles_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mall_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_base_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_base_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_base_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_base_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_additional\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_additional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_additional\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_additional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_quantities\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset_quantities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_metrics\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoefficients\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcoefficients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_directions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_directions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperturbation_seed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mperturbation_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_output_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbase_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# can be set to GPU if needed\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_existing_files\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\" Our saved results are structured as follows:\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03mwiggle_results: List of dictionaries containing wiggle test results\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mEach dictionary is of the form\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m'num_params':\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/minima-volume-project/minima_volume/perturb_funcs.py:367\u001b[0m, in \u001b[0;36manalyze_wiggles_metrics\u001b[0;34m(model_list, x_base_train, y_base_train, x_additional, y_additional, x_test, y_test, dataset_quantities, dataset_type, metrics, coefficients, num_directions, perturbation_seed, base_output_dir, device, batch_size, skip_existing_files)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (seed, perturb, perturb_norm) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(seed_list, random_perturbs, random_perturb_norms)):\n\u001b[1;32m    366\u001b[0m     filt_norm_perturb_vectors \u001b[38;5;241m=\u001b[39m filternorm_perturbation_vectors(perturb, norm_dict)\n\u001b[0;32m--> 367\u001b[0m     wiggle_result \u001b[38;5;241m=\u001b[39m \u001b[43mwiggle_evaluator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_perturber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperturber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mperturbation_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilt_norm_perturb_vectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoefficients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoefficients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     wiggle_result\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperturbation_seed\u001b[39m\u001b[38;5;124m'\u001b[39m: seed,\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperturbation_norm\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(perturb_norm\u001b[38;5;241m.\u001b[39mitem()),\n\u001b[1;32m    381\u001b[0m     })\n\u001b[1;32m    382\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mappend(wiggle_result)\n",
      "File \u001b[0;32m~/GitHub/minima-volume-project/minima_volume/perturb_funcs.py:242\u001b[0m, in \u001b[0;36mwiggle_evaluator\u001b[0;34m(model, model_perturber, points, labels, coefficients, perturbation_dict, metrics, batch_size)\u001b[0m\n\u001b[1;32m    240\u001b[0m delta_coeff \u001b[38;5;241m=\u001b[39m coeff \u001b[38;5;241m-\u001b[39m previous_coeff\n\u001b[1;32m    241\u001b[0m inc_perturbs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;241m*\u001b[39m delta_coeff \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m perturbation_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 242\u001b[0m \u001b[43mmodel_perturber\u001b[49m\u001b[38;5;241m.\u001b[39mapply_perturbation(inc_perturbs)\n\u001b[1;32m    243\u001b[0m previous_coeff \u001b[38;5;241m=\u001b[39m coeff\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# Forward pass (with batching if requested)\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/minima-volume-project/minima_volume/perturb_funcs.py:242\u001b[0m, in \u001b[0;36mwiggle_evaluator\u001b[0;34m(model, model_perturber, points, labels, coefficients, perturbation_dict, metrics, batch_size)\u001b[0m\n\u001b[1;32m    240\u001b[0m delta_coeff \u001b[38;5;241m=\u001b[39m coeff \u001b[38;5;241m-\u001b[39m previous_coeff\n\u001b[1;32m    241\u001b[0m inc_perturbs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;241m*\u001b[39m delta_coeff \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m perturbation_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 242\u001b[0m \u001b[43mmodel_perturber\u001b[49m\u001b[38;5;241m.\u001b[39mapply_perturbation(inc_perturbs)\n\u001b[1;32m    243\u001b[0m previous_coeff \u001b[38;5;241m=\u001b[39m coeff\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# Forward pass (with batching if requested)\u001b[39;00m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:634\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1112\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1090\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:494\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/minima-volume-project/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2188\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2185\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2187\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2188\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2190\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2193\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/minima-volume-project/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2257\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2255\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2257\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2258\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2260\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/minima-volume-project/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/minima-volume-project/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'mps'\n",
    "\n",
    "x_base_train = loaded_dataset['x_base_train'].to(device)\n",
    "y_base_train = loaded_dataset['y_base_train'].to(device)\n",
    "x_additional = loaded_dataset['x_additional'].to(device)\n",
    "y_additional = loaded_dataset['y_additional'].to(device)\n",
    "x_test = loaded_dataset['x_test'].to(device)\n",
    "y_test = loaded_dataset['y_test'].to(device)\n",
    "\n",
    "# Loss function and metrics already grabbed from the model module\n",
    "analyze_wiggles_metrics(\n",
    "    model_list = all_models, \n",
    "    x_base_train = x_base_train,\n",
    "    y_base_train = y_base_train, \n",
    "    x_additional = x_additional,\n",
    "    y_additional = y_additional,\n",
    "    x_test = x_test,\n",
    "    y_test = y_test, \n",
    "    dataset_quantities = dataset_quantities, \n",
    "    dataset_type = dataset_type, \n",
    "    metrics = {\"loss\": loss_fn, **other_metrics}, \n",
    "    coefficients = coefficients,\n",
    "    num_directions = num_directions,\n",
    "    perturbation_seed = perturbation_seed,\n",
    "    base_output_dir = base_output_dir,\n",
    "    device = device,  # can be set to GPU if needed\n",
    "    skip_existing_files = False\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\" Our saved results are structured as follows:\n",
    "wiggle_results: List of dictionaries containing wiggle test results\n",
    "Each dictionary is of the form\n",
    "{\n",
    "'loss':\n",
    "'coefficients':\n",
    "'accs':\n",
    "'perturbation_seed':\n",
    "'perturbation_norm':\n",
    "}\n",
    "model: PyTorch model used in analysis (state_dict will be saved)\n",
    "output_dir: Directory to save results (default: \"imgs/swiss/random_dirs\")\n",
    "filename: Name of output file (default: \"random_directions.npz\")\n",
    "**kwargs: Additional key-value pairs to be saved in the output file\n",
    "Typically:\n",
    "'additional_data':\n",
    "'model_trained_data':\n",
    "'dataset_type':\n",
    "'base_dataset_size': \n",
    "'test_loss':\n",
    "'test_accs':\n",
    "'num_params':\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530ae37-14b3-4d87-a88f-b8c868788a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minima-volume-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
